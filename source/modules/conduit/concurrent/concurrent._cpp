#include "engine.hpp"
#include "modules/conduit/concurrent/concurrent.hpp"
#include "modules/experiment/experiment.hpp"
#include "modules/problem/problem.hpp"
#include "modules/solver/solver.hpp"
#include <sys/wait.h>
#include <sys/types.h>
#include <fcntl.h>

#define PIPESIZE 1048576

void korali::conduit::Concurrent::initialize()
{
 // Instantiating Engine logger.
 _logger = new korali::Logger();

 if (_concurrentJobs < 1) _logger->logError("You need to define at least 1 concurrent job(s) for external models \n");
 _resultPipe.clear();
 _inputsPipe.clear();
 while(!_launcherQueue.empty()) _launcherQueue.pop();

 for (int i = 0; i < _concurrentJobs; i++) _resultPipe.push_back(std::vector<int>(2));
 for (int i = 0; i < _concurrentJobs; i++) _inputsPipe.push_back(std::vector<int>(2));
 for (int i = 0; i < _concurrentJobs; i++) _launcherQueue.push(i);

 // Opening Inter-process communicator pipes
 for (int i = 0; i < _concurrentJobs; i++)
 {
  if (pipe(_inputsPipe[i].data()) == -1) _logger->logError("Unable to create inter-process pipe. \n");
  if (pipe(_resultPipe[i].data()) == -1) _logger->logError("Unable to create inter-process pipe. \n");
  fcntl(_resultPipe[i][0], F_SETFL, fcntl(_resultPipe[i][0], F_GETFL) | O_NONBLOCK);
  fcntl(_resultPipe[i][1], F_SETFL, fcntl(_resultPipe[i][1], F_GETFL) | O_NONBLOCK);

  printf("Size: %lu\n", fcntl(_resultPipe[i][0], F_GETPIPE_SZ));
  int result = fcntl(_resultPipe[i][0], F_SETPIPE_SZ, PIPESIZE);
  printf("Size: %lu\n", fcntl(_resultPipe[i][0], F_GETPIPE_SZ));
 }
}

void korali::conduit::Concurrent::finalize()
{
 auto terminationJs = knlohmann::json();
 terminationJs["Conduit Action"] = "Terminate";

 std::string terminationString = terminationJs.dump();
 size_t terminationStringSize = terminationString.size();

 for(int i = 0; i < _concurrentJobs; i++)
 {
  write(_inputsPipe[i][1], &terminationStringSize, sizeof(size_t));
  write(_inputsPipe[i][1], terminationString.c_str(), terminationStringSize * sizeof(char));
 }

 for(int i = 0; i < _concurrentJobs; i++)
 {
  int status;
  pid_t processId;
  processId = ::wait(&status);
 }

 for (int i = 0; i < _concurrentJobs; i++)
 {
  close(_resultPipe[i][1]); // Closing pipes
  close(_resultPipe[i][0]); // Closing pipes
  close(_inputsPipe[i][1]); // Closing pipes
  close(_inputsPipe[i][0]); // Closing pipes
 }

 korali::Conduit::finalize();
}

void korali::conduit::Concurrent::initServer()
{
 for(int i = 0; i < _concurrentJobs; i++)
 {
  pid_t processId = fork();
  if (processId == 0) worker(i);
  _workerPids.push_back(processId);
 }
}

void korali::conduit::Concurrent::worker(int workerId)
{
 while(true)
 {
  size_t inputStringSize;
  read(_inputsPipe[workerId][0], &inputStringSize, sizeof(size_t));

  char inputString[inputStringSize + 1];
  read(_inputsPipe[workerId][0], inputString, inputStringSize * sizeof(char));
  inputString[inputStringSize] = '\0';

  auto actionJs = knlohmann::json::parse(inputString);

  if (actionJs["Conduit Action"] == "Terminate") exit(0);

  if (actionJs["Conduit Action"] == "Process Sample")
  {
   korali::Sample sample;
   sample._js.getJson() = actionJs;

   size_t experimentId = sample["Experiment Id"];
   std::string operation = sample["Operation"];

   korali::Engine* engine = _engineStack.top();

   if (sample["Module"] == "Problem")
    engine->_experimentVector[experimentId]->_problem->runOperation(operation, sample);

   if (sample["Module"] == "Solver")
    engine->_experimentVector[experimentId]->_solver->runOperation(operation, sample);

   std::string resultString = sample._js.getJson().dump();
   size_t resultStringSize = resultString.size();

   write(_resultPipe[workerId][1], &resultStringSize, sizeof(size_t));
   write(_resultPipe[workerId][1], resultString.c_str(), resultStringSize * sizeof(char));
  }

  if (actionJs["Conduit Action"] == "Stack Engines")
   for (size_t i = 0; i < actionJs["Engines"].size(); i++)
   _engineStack.push(korali::Engine::deserialize(actionJs["Engines"][i]));

  if (actionJs["Conduit Action"] == "Pop Engine")  _engineStack.pop();
 }
}

void korali::conduit::Concurrent::processSample(korali::Sample& sample)
{
 korali::Engine* engine = _engineStack.top();

 while (_launcherQueue.empty())
 {
  sample._state = SampleState::waiting;
  co_switch(engine->_currentExperiment->_thread);
 }

 int launcherId = _launcherQueue.front(); _launcherQueue.pop();

 auto js = knlohmann::json();
 js["Start Time"] = std::chrono::duration<double>(std::chrono::high_resolution_clock::now()-_startTime).count() + _cumulativeTime;

 auto sampleJs = sample._js.getJson();
 sampleJs["Conduit Action"] = "Process Sample";

 std::string inputString = sampleJs.dump();
 size_t inputStringSize = inputString.size();

 write(_inputsPipe[launcherId][1], &inputStringSize, sizeof(size_t));
 write(_inputsPipe[launcherId][1], inputString.c_str(), inputStringSize * sizeof(char));

 int readBytes = -1;
 while(readBytes < 0)
 {
  // Check for child defunction
  for (int i = 0; i < _workerPids.size(); i++)
  {
   int status;
   pid_t result = waitpid(_workerPids[i], &status, WNOHANG);
   if (result != 0) _logger->logError("Worker %i (Pid: %d) exited unexpectedly.\n", i, _workerPids[i]);
  }

  size_t resultStringSize;
  readBytes = read(_resultPipe[launcherId][0], &resultStringSize, sizeof(size_t));

  if(readBytes > 0)
  {
   char resultString[resultStringSize + 1];
   while(read(_resultPipe[launcherId][0], resultString, resultStringSize * sizeof(char)) < 0);

   resultString[resultStringSize] = '\0';
   sample._js.getJson() = knlohmann::json::parse(resultString);

   _launcherQueue.push(launcherId);
  }
  else
  {
   sample._state = SampleState::waiting;
   co_switch(engine->_currentExperiment->_thread);
  }
 }

 js["End Time"] = std::chrono::duration<double>(std::chrono::high_resolution_clock::now()-_startTime).count() + _cumulativeTime;
 js["Solver Id"] = engine->_currentExperiment->_experimentId;
 js["Current Generation"] = engine->_currentExperiment->_currentGeneration;
 __profiler["Timelines"]["Worker " + std::to_string(launcherId)] += js;

}

void korali::conduit::Concurrent::stackEngine(korali::Engine* engine)
{
 auto newStack = _engineStack;
 newStack.push(engine);

 for (size_t i = 0; i < newStack.size() - 1; i++) popEngine();

 _engineStack = newStack;

 size_t stackSize = newStack.size();
 std::vector<korali::Engine*> engineList;
 for (size_t i = 0; i < stackSize; i++) { engineList.push_back(newStack.top()); newStack.pop(); }

 auto stackJs = knlohmann::json();
 stackJs["Conduit Action"] = "Stack Engines";

 for (int i = 0; i < stackSize; i++)
  engineList[stackSize-i-1]->serialize(stackJs["Engines"][i]);

 std::string stackString = stackJs.dump();
 size_t stackStringSize = stackString.size();

 for(int i = 0; i < _concurrentJobs; i++)
 {
  write(_inputsPipe[i][1], &stackStringSize, sizeof(size_t));
  write(_inputsPipe[i][1], stackString.c_str(), stackStringSize * sizeof(char));
 }
}

void korali::conduit::Concurrent::popEngine()
{
 _engineStack.pop();

  auto engineJs = knlohmann::json();
  engineJs["Conduit Action"] = "Pop Engine";

  std::string engineString = engineJs.dump();
  size_t engineStringSize = engineString.size();

  for(int i = 0; i < _concurrentJobs; i++)
  {
   write(_inputsPipe[i][1], &engineStringSize, sizeof(size_t));
   write(_inputsPipe[i][1], engineString.c_str(), engineStringSize * sizeof(char));
  }
}
