#include "engine.hpp"
#include "modules/conduit/distributed/distributed.hpp"
#include "modules/experiment/experiment.hpp"
#include "modules/problem/problem.hpp"
#include "modules/solver/solver.hpp"

#ifdef _KORALI_USE_MPI

#define MPI_TAG_ACTION_JSON_SIZE 1
#define MPI_TAG_ACTION_JSON_CONTENT 2

MPI_Comm __KoraliTeamComm;
MPI_Comm getKoraliMPIComm() { return __KoraliTeamComm; }
long int getKoraliMPICommPointer() { return (long int)(&__KoraliTeamComm); }
#endif

void korali::conduit::Distributed::initialize()
{
 // Instantiating Engine logger.
 _logger = new korali::Logger();

 #ifdef _KORALI_USE_MPI
 _rankCount = 1;
 _rankId = 0;

 if (_communicator == 0) _communicator = MPI_COMM_WORLD;

 MPI_Comm_size(_communicator, &_rankCount);
 MPI_Comm_rank(_communicator, &_rankId);
 #endif

 #ifndef _KORALI_USE_MPI
  _logger->logError("Running an Distributed-based Korali application, but Korali was installed without support for Distributed.\n");
 #endif

 #ifdef _KORALI_USE_MPI
 MPI_Barrier(_communicator);
 _continueEvaluations = true;

 if (_rankCount == 1) _logger->logError("Korali Distributed applications require at least 2 Distributed ranks to run.\n");

 _teamCount = (_rankCount-1) / _workersPerTeam;
 _teamId = -1;
 _localRankId = -1;

 int currentRank = 0;
 _teamWorkers.clear();
 _teamQueue = std::queue<int>();
 while(!_teamQueue.empty()) _teamQueue.pop();
 for (int i = 0; i < _teamCount; i++)
 {
  _teamQueue.push(i);
  for (int j = 0; j < _workersPerTeam; j++)
  {
   if (currentRank == _rankId)
   {
    _teamId = i;
    _localRankId = j;
   }
   _teamWorkers[i].push_back(currentRank++);
  }
 }

 MPI_Comm_split(_communicator, _teamId, _rankId, &__KoraliTeamComm);

 int mpiSize = -1;
 MPI_Comm_size(_communicator, &mpiSize);

 if(isRoot()) if (_rankCount < _workersPerTeam + 1)
 _logger->logError("You are running Korali with %d ranks. However, you need at least %d ranks to have at least one worker team. \n", _rankCount, _workersPerTeam + 1 );

 MPI_Barrier(_communicator);

 #endif
}

void korali::conduit::Distributed::initServer()
{
 if (!isRoot()) workerThread();
}

void korali::conduit::Distributed::update(korali::Sample& sample)
{
 if (_localRankId == 0)
 {
   std::string resultJsonString = sample._js.getJson().dump();
   size_t resultJsonSize = resultJsonString.size();
   MPI_Send(&resultJsonSize, 1, MPI_UNSIGNED_LONG, getRootRank(), MPI_TAG_ACTION_JSON_SIZE, _communicator);
   MPI_Send(resultJsonString.c_str(), resultJsonSize, MPI_CHAR, getRootRank(), MPI_TAG_ACTION_JSON_CONTENT, _communicator);
 }
}

void korali::conduit::Distributed::finalize()
{
 #ifdef _KORALI_USE_MPI
 auto terminationJs = knlohmann::json();
 terminationJs["Conduit Action"] = "Terminate";

 std::string terminationString = terminationJs.dump();
 size_t terminationStringSize = terminationString.size();

 if (isRoot())
 {
  for (int i = 0; i < _teamCount; i++)
   for (int j = 0; j < _workersPerTeam; j++)
   {
    MPI_Send(&terminationStringSize, 1, MPI_UNSIGNED_LONG, _teamWorkers[i][j], MPI_TAG_ACTION_JSON_SIZE, _communicator);
    MPI_Send(terminationString.c_str(), terminationStringSize, MPI_CHAR, _teamWorkers[i][j], MPI_TAG_ACTION_JSON_CONTENT, _communicator);
   }
 }

 MPI_Barrier(_communicator);
 #endif

 korali::Conduit::finalize();
}


void korali::conduit::Distributed::workerThread()
{
 #ifdef _KORALI_USE_MPI
 if (_teamId == -1) return;

 while (true)
 {
  size_t jsonStringSize;
  MPI_Recv(&jsonStringSize, 1, MPI_UNSIGNED_LONG, getRootRank(), MPI_TAG_ACTION_JSON_SIZE, _communicator, MPI_STATUS_IGNORE);

  char jsonStringChar[jsonStringSize + 1];
  MPI_Recv(jsonStringChar, jsonStringSize, MPI_CHAR, getRootRank(), MPI_TAG_ACTION_JSON_CONTENT, _communicator, MPI_STATUS_IGNORE);

  jsonStringChar[jsonStringSize] = '\0';
  auto actionJs = knlohmann::json::parse(jsonStringChar);

  if (actionJs["Conduit Action"] == "Terminate") return;

  if (actionJs["Conduit Action"] == "Process Sample") initiateSample(actionJs);

  if (actionJs["Conduit Action"] == "Stack Engines")
   for (size_t i = 0; i < actionJs["Engines"].size(); i++)
   _engineStack.push(korali::Engine::deserialize(actionJs["Engines"][i]));

  if (actionJs["Conduit Action"] == "Pop Engine")  _engineStack.pop();

  MPI_Barrier(__KoraliTeamComm);
 }
 #endif
}

void korali::conduit::Distributed::processSample(korali::Sample& sample)
{
 korali::Engine* engine = _engineStack.top();

 #ifdef _KORALI_USE_MPI

 int teamId = -1;

 if (JsonInterface::isDefined(sample._js.getJson(), "['Worker']"))
 {
  teamId = sample["Worker"];
 }
 else
 {
  while (_teamQueue.empty())
  {
   sample._state = SampleState::waiting;
   co_switch(engine->_currentExperiment->_thread);
  }
  teamId = _teamQueue.front(); _teamQueue.pop();
 }

 auto sampleJs = sample._js.getJson();
 sampleJs["Conduit Action"] = "Process Sample";

 std::string sampleJsonString = sampleJs.dump();
 size_t sampleJsonSize = sampleJsonString.size();

 for (int i = 0; i < _workersPerTeam; i++)
 {
  int workerId = _teamWorkers[teamId][i];
  MPI_Send(&sampleJsonSize, 1, MPI_UNSIGNED_LONG, workerId, MPI_TAG_ACTION_JSON_SIZE, _communicator);
  MPI_Send(sampleJsonString.c_str(), sampleJsonSize, MPI_CHAR, workerId, MPI_TAG_ACTION_JSON_CONTENT, _communicator);
 }

 size_t resultJsonSize;
 MPI_Request resultJsonRequest;
 MPI_Irecv(&resultJsonSize, 1, MPI_UNSIGNED_LONG, _teamWorkers[teamId][0], MPI_TAG_ACTION_JSON_SIZE, _communicator, &resultJsonRequest);

 auto timelineJs = knlohmann::json();
 timelineJs["Start Time"] = std::chrono::duration<double>(std::chrono::high_resolution_clock::now()-_startTime).count() + _cumulativeTime;

 int flag = 0;
 while(flag == 0)
 {
  MPI_Test(&resultJsonRequest, &flag, MPI_STATUS_IGNORE);
  if (flag)
  {
    char resultStringChar[resultJsonSize + 1];
    MPI_Recv(resultStringChar, resultJsonSize, MPI_CHAR, _teamWorkers[teamId][0], MPI_TAG_ACTION_JSON_CONTENT, _communicator, MPI_STATUS_IGNORE);
    resultStringChar[resultJsonSize] = '\0';
    sample._js.getJson() = knlohmann::json::parse(resultStringChar);
    _teamQueue.push(teamId);
  }
  else
  {
   sample._state = SampleState::waiting;
   co_switch(engine->_currentExperiment->_thread);
  }
 }

 timelineJs["End Time"] = std::chrono::duration<double>(std::chrono::high_resolution_clock::now()-_startTime).count() + _cumulativeTime;
 timelineJs["Solver Id"] = engine->_currentExperiment->_experimentId;
 timelineJs["Current Generation"] = engine->_currentExperiment->_currentGeneration;
 __profiler["Timelines"]["Worker " + std::to_string(teamId)] += timelineJs;

 #endif
}

void korali::conduit::Distributed::stackEngine(korali::Engine* engine)
{
 #ifdef _KORALI_USE_MPI

 auto newStack = _engineStack;
 newStack.push(engine);

 for (size_t i = 0; i < newStack.size() - 1; i++) popEngine();

 _engineStack = newStack;

 size_t stackSize = newStack.size();
 std::vector<korali::Engine*> engineList;
 for (size_t i = 0; i < stackSize; i++) { engineList.push_back(newStack.top()); newStack.pop(); }

 auto stackJs = knlohmann::json();
 stackJs["Conduit Action"] = "Stack Engines";

 for (int i = 0; i < stackSize; i++)
  engineList[stackSize-i-1]->serialize(stackJs["Engines"][i]);

 std::string stackString = stackJs.dump();
 size_t stackStringSize = stackString.size();

 for (int i = 0; i < _teamCount; i++)
  for (int j = 0; j < _workersPerTeam; j++)
  {
   MPI_Send(&stackStringSize, 1, MPI_UNSIGNED_LONG, _teamWorkers[i][j], MPI_TAG_ACTION_JSON_SIZE, _communicator);
   MPI_Send(stackString.c_str(), stackStringSize, MPI_CHAR, _teamWorkers[i][j], MPI_TAG_ACTION_JSON_CONTENT, _communicator);
  }

 #endif
}

void korali::conduit::Distributed::popEngine()
{
 #ifdef _KORALI_USE_MPI

 _engineStack.pop();

 auto engineJs = knlohmann::json();
 engineJs["Conduit Action"] = "Pop Engine";

 std::string engineString = engineJs.dump();
 size_t engineStringSize = engineString.size();

 if (isRoot())
 {
  for (int i = 0; i < _teamCount; i++)
   for (int j = 0; j < _workersPerTeam; j++)
   {
    MPI_Send(&engineStringSize, 1, MPI_UNSIGNED_LONG, _teamWorkers[i][j], MPI_TAG_ACTION_JSON_SIZE, _communicator);
    MPI_Send(engineString.c_str(), engineStringSize, MPI_CHAR, _teamWorkers[i][j], MPI_TAG_ACTION_JSON_CONTENT, _communicator);
   }
 }

 #endif
}

size_t korali::conduit::Distributed::maxConcurrency()
{
 return _teamCount;
}

int korali::conduit::Distributed::getRootRank()
{
 #ifdef _KORALI_USE_MPI
 return _rankCount-1;
 #endif

 return 0;
}

bool korali::conduit::Distributed::isRoot()
{
 #ifdef _KORALI_USE_MPI
 return _rankId == getRootRank();
 #endif

 return true;
}

void korali::conduit::Distributed::abort()
{
 #ifdef _KORALI_USE_MPI
 MPI_Abort(_communicator, -1);
 #endif
}
