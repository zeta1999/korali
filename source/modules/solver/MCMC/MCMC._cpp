#include "modules/solver/MCMC/MCMC.hpp"
#include "modules/problem/problem.hpp"
#include "modules/experiment/experiment.hpp"
#include "modules/conduit/conduit.hpp"

#include <numeric>
#include <limits>
#include <chrono>

#include <gsl/gsl_sort_vector.h>
#include <gsl/gsl_matrix.h>
#include <gsl/gsl_linalg.h>
#include <gsl/gsl_statistics.h>
#include <gsl/gsl_multimin.h>

void korali::solver::MCMC::setInitialConfiguration()
{
 if(_chainCovarianceScaling <= 0.0) _k->_logger->logError("Chain Covariance Scaling must be larger 0.0 (is %lf).\n", _chainCovarianceScaling);
 if(_leap < 1) _k->_logger->logError( "Leap must be larger 0 (is %zu).\n", _leap);
 if(_burnIn < 0) _k->_logger->logError( "Burn In must be larger equal 0 (is %zu).\n", _burnIn);
 if(_rejectionLevels < 1) _k->_logger->logError( "Rejection Levels must be larger 0 (is %zu).\n", _rejectionLevels);
 if(_nonAdaptionPeriod < 0) _k->_logger->logError( "Non Adaption Period must be larger equal 0 (is %zu).\n", _nonAdaptionPeriod);

 // Allocating MCMC memory
 _chainCandidate.resize(_rejectionLevels);
 for(size_t i = 0; i < _rejectionLevels; i++) _chainCandidate[i].resize(_k->_variables.size());

 _choleskyDecompositionCovariance.resize(_k->_variables.size()*_k->_variables.size());
 _chainLeader.resize(_k->_variables.size());
 _chainCandidatesEvaluations.resize(_rejectionLevels);
 _rejectionAlphas.resize(_rejectionLevels);
 _chainMean.resize(_k->_variables.size());
 _chainCovariancePlaceholder.resize(_k->_variables.size()*_k->_variables.size());
 _chainCovariance.resize(_k->_variables.size()*_k->_variables.size());
 _choleskyDecompositionChainCovariance.resize(_k->_variables.size()*_k->_variables.size());

 std::fill(std::begin(_choleskyDecompositionCovariance), std::end(_choleskyDecompositionCovariance), 0.0);
 std::fill(std::begin(_choleskyDecompositionChainCovariance), std::end(_choleskyDecompositionChainCovariance), 0.0);

 for(size_t i = 0; i < _k->_variables.size(); i++) _chainLeader[i]  = _k->_variables[i]->_initialMean;
 for(size_t i = 0; i < _k->_variables.size(); i++) _choleskyDecompositionCovariance[i*_k->_variables.size()+i] = _k->_variables[i]->_initialStandardDeviation;

 // Init Generation
 _acceptanceCount = 0;
 _proposedSampleCount = 0;
 _chainLength = 0;
 _chainLeaderEvaluation = -std::numeric_limits<double>::infinity();
 _acceptanceRate  = 1.0;

 (*_k)["Results"]["Sample Database"]  = {};
}

void korali::solver::MCMC::runGeneration()
{
 if (_k->_currentGeneration == 1) setInitialConfiguration();

 bool _sampleAccepted = false;

 for(size_t i = 0; i < _rejectionLevels && _sampleAccepted == false; i++)
 {
  generateCandidate(i);

  auto sample = korali::Sample();

  _modelEvaluationCount++;
  sample["Parameters"] = _chainCandidate[i];
  sample["Sample Id"] = _sampleDatabase.size();
  sample["Module"] = "Problem";
  sample["Operation"] = "Evaluate";
  _conduit->start(sample);
  _conduit->wait(sample);
  double evaluation = sample["P(x)"];

  _chainCandidatesEvaluations[i] = evaluation;

  // Processing Result
  double denom;
  double _rejectionAlpha = recursiveAlpha(denom, _chainLeaderEvaluation, &_chainCandidatesEvaluations[0], i);

  if ( _rejectionAlpha == 1.0 || _rejectionAlpha > _uniformGenerator->getRandomNumber() )
  {
    _acceptanceCount++;
    _sampleAccepted = true;
    _chainLeaderEvaluation = _chainCandidatesEvaluations[i];
    _chainLeader = _chainCandidate[i];
  }
 }

 if ( (_chainLength >= _burnIn) && (_k->_currentGeneration % _leap == 0) )
 {
  _sampleDatabase.push_back(_chainLeader);
  _sampleEvaluationDatabase.push_back(_chainLeaderEvaluation);
  (*_k)["Results"]["Sample Database"] += _chainLeader;
 }
 
 updateState();
 _chainLength++;

}


void korali::solver::MCMC::choleskyDecomp(const std::vector<double>& inC, std::vector<double>& outL) const
{
  gsl_matrix* A = gsl_matrix_alloc(_k->_variables.size(), _k->_variables.size());

  for(size_t d = 0; d < _k->_variables.size(); ++d)  for(size_t e = 0; e < d; ++e)
  {
      gsl_matrix_set(A,d,e,inC[d*_k->_variables.size()+e]);
      gsl_matrix_set(A,e,d,inC[e*_k->_variables.size()+d]);
  }
  for(size_t d = 0; d < _k->_variables.size(); ++d) gsl_matrix_set(A,d,d,inC[d*_k->_variables.size()+d]);

  int err = gsl_linalg_cholesky_decomp1(A);

  if (err == GSL_EDOM)
  {
    _k->_logger->logWarning("Normal", "Chain Covariance negative definite (not updating Cholesky Decomposition of Chain Covariance).\n");
  }
  else
  {
    for(size_t d = 0; d < _k->_variables.size(); ++d)  for(size_t e = 0; e < d; ++e)
    {
      outL[d*_k->_variables.size()+e] = gsl_matrix_get(A,d,e);
    }
    for(size_t d = 0; d < _k->_variables.size(); ++d) outL[d*_k->_variables.size()+d] = gsl_matrix_get(A,d,d);
  }

  gsl_matrix_free(A);
}

double korali::solver::MCMC::recursiveAlpha(double& deonominator, const double leaderLoglikelihood, const double* loglikelihoods, size_t N) const
{
 // recursive formula from Trias[2009]

 if(N==0)
 {
  deonominator = exp(leaderLoglikelihood);
  return std::min(1.0, exp(loglikelihoods[0] - leaderLoglikelihood));
 }
 else
 {
  // revert sample array
  double* reversedLogLikelihoods = new double[N];
  for(size_t i = 0; i < N; ++i) reversedLogLikelihoods[i] = loglikelihoods[N-1-i];
  
  // update numerator (w. recursive calls)
  double numerator = std::exp(loglikelihoods[N]);
  for(size_t i = 0; i < N; ++i)
  {
   double dummyDenominator;
   double alphaNumerator = recursiveAlpha(dummyDenominator, loglikelihoods[N], reversedLogLikelihoods, i);
   numerator *=  ( 1.0 - alphaNumerator );
  }
  delete [] reversedLogLikelihoods;

  if (numerator == 0.0) return 0.0;

  // update denomiator
  double denominatorStar;
  double alphaDenominator = recursiveAlpha(denominatorStar, leaderLoglikelihood, loglikelihoods, N-1);
  deonominator = denominatorStar * (1.0 - alphaDenominator);

  return std::min(1.0, numerator/deonominator);
 }
}


void korali::solver::MCMC::generateCandidate(size_t sampleIdx)
{  
 _proposedSampleCount++;

 if(sampleIdx == 0) for (size_t d = 0; d < _k->_variables.size(); ++d) _chainCandidate[sampleIdx][d] = _chainLeader[d];
 else for (size_t d = 0; d < _k->_variables.size(); ++d) _chainCandidate[sampleIdx][d] = _chainCandidate[sampleIdx-1][d];

 if ( (_useAdaptiveSampling == false) || (_sampleDatabase.size() <= _nonAdaptionPeriod + _burnIn))
     for (size_t d = 0; d < _k->_variables.size(); ++d) for (size_t e = 0; e < _k->_variables.size(); ++e) _chainCandidate[sampleIdx][d] += _choleskyDecompositionCovariance[d*_k->_variables.size()+e] * _normalGenerator->getRandomNumber();
 else
     for (size_t d = 0; d < _k->_variables.size(); ++d) for (size_t e = 0; e < _k->_variables.size(); ++e) _chainCandidate[sampleIdx][d] += _choleskyDecompositionChainCovariance[d*_k->_variables.size()+e] * _normalGenerator->getRandomNumber();
}

void korali::solver::MCMC::updateState()
{

 _acceptanceRate = ( (double)_acceptanceCount/ (double)_chainLength );

 if(_sampleDatabase.size() == 0) return;
 if(_sampleDatabase.size() == 1) { for (size_t d = 0; d < _k->_variables.size(); d++) _chainMean[d] = _chainLeader[d]; return; }

 for (size_t d = 0; d < _k->_variables.size(); d++) for (size_t e = 0; e < d; e++)
 {
   _chainCovariancePlaceholder[d*_k->_variables.size()+e] = (_chainMean[d] - _chainLeader[d]) * (_chainMean[e] - _chainLeader[e]);
   _chainCovariancePlaceholder[e*_k->_variables.size()+d] = (_chainMean[d] - _chainLeader[d]) * (_chainMean[e] - _chainLeader[e]);
 }
 for (size_t d = 0; d < _k->_variables.size(); d++) _chainCovariancePlaceholder[d*_k->_variables.size()+d] = (_chainMean[d] - _chainLeader[d]) * (_chainMean[d] - _chainLeader[d]);

 // Chain Mean
 for (size_t d = 0; d < _k->_variables.size(); d++) _chainMean[d] = (_chainMean[d] * (_sampleDatabase.size()-1) + _chainLeader[d]) / _sampleDatabase.size();

 for (size_t d = 0; d < _k->_variables.size(); d++) for (size_t e = 0; e < d; e++)
 {
   _chainCovariance[d*_k->_variables.size()+e] = (_sampleDatabase.size()-2.0)/(_sampleDatabase.size()-1.0) * _chainCovariance[d*_k->_variables.size()+e] + (_chainCovarianceScaling/_sampleDatabase.size())*_chainCovariancePlaceholder[d*_k->_variables.size()+e];
   _chainCovariance[e*_k->_variables.size()+d] = (_sampleDatabase.size()-2.0)/(_sampleDatabase.size()-1.0) * _chainCovariance[d*_k->_variables.size()+e] + (_chainCovarianceScaling/_sampleDatabase.size())*_chainCovariancePlaceholder[d*_k->_variables.size()+e];
 }
 for (size_t d = 0; d < _k->_variables.size(); d++)
 _chainCovariance[d*_k->_variables.size()+d] = (_sampleDatabase.size()-2.0)/(_sampleDatabase.size()-1.0) * _chainCovariance[d*_k->_variables.size()+d] + (_chainCovarianceScaling/_sampleDatabase.size())*_chainCovariancePlaceholder[d*_k->_variables.size()+d];

 if (( _useAdaptiveSampling == true) && (_sampleDatabase.size() > _nonAdaptionPeriod)) choleskyDecomp(_chainCovariance, _choleskyDecompositionChainCovariance);
}


void korali::solver::MCMC::printGenerationBefore() { return; }

void korali::solver::MCMC::printGenerationAfter()
{
 _k->_logger->logInfo("Minimal", "Database Entries %ld\n", _sampleDatabase.size());

 _k->_logger->logInfo("Normal", "Accepted Samples: %zu\n", _acceptanceCount);
 _k->_logger->logInfo("Normal", "Acceptance Rate Proposals: %.2f%%\n", 100*_acceptanceRate);

 _k->_logger->logInfo("Detailed", "Current Sample:\n");
 for (size_t d = 0; d < _k->_variables.size(); d++)  _k->_logger->logData("Detailed", "         %s = %+6.3e\n", _k->_variables[d]->_name.c_str(), _chainLeader[d]);

 _k->_logger->logInfo("Detailed", "Current Chain Mean:\n");
 for (size_t d = 0; d < _k->_variables.size(); d++) _k->_logger->logData("Detailed", "         %s = %+6.3e\n", _k->_variables[d]->_name.c_str(), _chainMean[d]);
 _k->_logger->logInfo("Detailed", "Current Chain Covariance:\n");
 for (size_t d = 0; d < _k->_variables.size(); d++)
 {
  for (size_t e = 0; e <= d; e++) _k->_logger->logData("Detailed", "         %+6.3e  ", _chainCovariance[d*_k->_variables.size()+e]);
  _k->_logger->logInfo("Detailed", "\n");
 }
}

void korali::solver::MCMC::finalize()
{
 _k->_logger->logInfo("Minimal", "Number of Generated Samples: %zu\n", _proposedSampleCount);
 _k->_logger->logInfo("Minimal", "Acceptance Rate: %.2f%%\n", 100*_acceptanceRate);
 if (_sampleDatabase.size() == _maxSamples) _k->_logger->logInfo("Minimal", "Max Samples Reached.\n");
 (*_k)["Results"]["Sample Database"] = _sampleDatabase;
}
