#include "modules/solver/Nested/Nested.hpp"
#include "modules/conduit/conduit.hpp"
#include "modules/experiment/experiment.hpp"

#include <gsl/gsl_vector.h>
#include <gsl/gsl_matrix.h>
#include <gsl/gsl_linalg.h>

#include <algorithm> //sort
#include <numeric>
#include <limits>
#include <chrono>

void korali::solver::Nested::setInitialConfiguration()
{
 if(_covarianceScaling <= 0.0) _k->_logger->logError("Covariance Scaling must be larger 0.0 (is %lf).\n", _covarianceScaling);
 if(_maxGainFactor < 0.0) _k->_logger->logError("Max Gain Factor must be larger equal 0.0 (is %lf).\n", _maxGainFactor);
 
 if((_resamplingMethod != "MCMC") && (_resamplingMethod != "Box") && (_resamplingMethod != "Ellipse")) _k->_logger->logError("Only accepted Resampling Method are 'MCMC', 'Box' and 'Ellipse' (is %s).\n", _resamplingMethod.c_str());

 if(_proposalUpdateFrequency == 0) _k->_logger->logError("Proposal Update Frequency must be larger 0");

 for(size_t d = 0; d < _k->_variables.size(); ++d)
 {
    if (_k->_distributions[_k->_variables[d]->_distributionIndex]->_type != "Univariate/Uniform") _k->_logger->logError("Only 'Univariate/Uniform' priors allowed (is %s).\n", _k->_distributions[_k->_variables[d]->_distributionIndex]->_type.c_str());
 }
 
 if((_resamplingMethod == "Ellipse") && (_k->_variables.size() == 2)) _k->_logger->logError("Resampling Method Ellipse only suitable for problems of dim larger 2.");

 _candidateLogLikelihoods.resize(_batchSize);
 _candidateLogPriors.resize(_batchSize);
 _candidates.resize(_batchSize);
 for(size_t i = 0; i < _batchSize; i++) _candidates[i].resize(_k->_variables.size());
 
 _liveLogLikelihoods.resize(_numberLivePoints);
 _liveLogPriors.resize(_numberLivePoints);
 _liveSamplesRank.resize(_numberLivePoints);
 _liveSamples.resize(_numberLivePoints);
 for(size_t i = 0; i < _numberLivePoints; i++) _liveSamples[i].resize(_k->_variables.size());
  
 _databaseEntries = 0;
 _sampleLogLikelihoodDatabase.resize(0);
 _sampleLogPriorDatabase.resize(0);
 _sampleLogWeightDatabase.resize(0);
 _sampleDatabase.resize(0);
 
 _covarianceMatrix.resize(_k->_variables.size()*_k->_variables.size());
 _domainMean.resize(_k->_variables.size());
 _boxLowerBound.resize(_k->_variables.size());
 _boxUpperBound.resize(_k->_variables.size());
 _ellipseAxes.resize(_k->_variables.size());
 for(size_t i = 0; i < _k->_variables.size(); i++) _ellipseAxes[i].resize(_k->_variables.size());

 // Init Generation
 _logEvidence          = std::numeric_limits<double>::lowest();
 _expectedLogShrinkage = log((_numberLivePoints+1.)/_numberLivePoints);
 _logVolume            = 0.;
 _logEvidenceVar       = 0.;
 _information          = 0.;
 _lastAccepted         = 0;
 _acceptedSamples      = 0;
 _generatedSamples     = 0;
 _lStarOld             = std::numeric_limits<double>::lowest();
 _lStar                = std::numeric_limits<double>::lowest();

 (*_k)["Results"]["Posterior Samples"] = {};
}

void korali::solver::Nested::runGeneration()
{
  if (_k->_currentGeneration == 1) 
  { 
    setInitialConfiguration(); 
    runFirstGeneration(); 

    return; 
  };

  // Generation > 1
  prepareGeneration();

  std::vector<korali::Sample> samples(_batchSize);

  for (size_t c = 0; c < _batchSize; c++)
  {
   samples[c]["Module"]     = "Problem";
   samples[c]["Operation"]  = "Evaluate";
   samples[c]["Parameters"] = _candidates[c];
   samples[c]["Sample Id"]  = c;
   _conduit->start(samples[c]);
   _modelEvaluationCount++;
   _generatedSamples++;
  }


  size_t finishedCandidatesCount = 0;
  while (finishedCandidatesCount < _batchSize)
  {
   size_t finishedId = _conduit->waitAny(samples);

   _candidateLogLikelihoods[finishedId] = samples[finishedId]["logLikelihood"];
   _candidateLogPriors[finishedId]      = samples[finishedId]["logPrior"];
   finishedCandidatesCount++;

  }

  processGeneration();
  

  return;
}


void korali::solver::Nested::runFirstGeneration()
{
  for(size_t i = 0; i < _numberLivePoints; i++)
     for (size_t d = 0; d < _k->_variables.size(); d++) 
       _liveSamples[i][d] = _k->_distributions[_k->_variables[d]->_distributionIndex]->getRandomNumber();
 
  std::vector<korali::Sample> samples(_numberLivePoints);

  for (size_t c = 0; c < _numberLivePoints; c++)
  {
    samples[c]["Module"]     = "Problem";
    samples[c]["Operation"]  = "Evaluate";
    samples[c]["Parameters"] = _liveSamples[c];
    samples[c]["Sample Id"]  = c;
    _conduit->start(samples[c]);
    _modelEvaluationCount++;
    _generatedSamples++;
  }

  size_t finishedCandidatesCount = 0;
  while (finishedCandidatesCount < _numberLivePoints)
  {
   size_t finishedId = _conduit->waitAny(samples);

   _liveLogLikelihoods[finishedId] = samples[finishedId]["logLikelihood"];
   _liveLogPriors[finishedId]      = samples[finishedId]["logPrior"];
   
   finishedCandidatesCount++;
  }

  sortLiveSamplesAscending();
 
  _lStar = _liveLogLikelihoods[_liveSamplesRank[0]];

  return;
}


void korali::solver::Nested::prepareGeneration()
{
  
  _maxEvaluation = _liveLogLikelihoods[_liveSamplesRank[_numberLivePoints-1]];
  _numberEffectiveSamples = calcEffectiveSamples();
  
  if (_resamplingMethod == "MCMC") 
  { 
    updateMeanAndCovariance(); 
    generateCandidatesFromMCMC(); 
  }
  else if (_resamplingMethod == "Box")
  {
    updateBox();
    generateCandidatesFromBox();
  }
  else /* (_resamplingMethod == "Ellipse") */ 
  {
    updateEllipse();   
    generateCandidatesFromEllipse();
  }
  
  return;
}


void korali::solver::Nested::processGeneration()
{
  size_t sampleIdx = _liveSamplesRank[0];
  size_t acceptedBefore = _acceptedSamples;
  for (size_t c = 0; c < _batchSize ; ++c)
  {
    if(_candidateLogLikelihoods[c] < _lStar) continue;
    _acceptedSamples++;
    
    // update evidence & domain
    double logVolumeOld   = _logVolume;
    double informationOld = _information;
    double logEvidenceOld = _logEvidence;
    
    _logVolume -= _expectedLogShrinkage;

    double dLogVol = log(0.5*exp(logVolumeOld)-0.5*exp(_logVolume));
    _logWeight   = safeLogPlus(_lStar, _lStarOld) + dLogVol;
    _logEvidence = safeLogPlus(_logEvidence, _logWeight);

    double evidenceTerm = exp(_lStarOld-_logEvidence) * _lStarOld 
        + exp(_lStar-_logEvidence) * _lStar;

    _information  = exp(dLogVol) * evidenceTerm 
       + exp(logEvidenceOld - _logEvidence) * (informationOld + logEvidenceOld) 
       - _logEvidence;
       
    _logEvidenceVar += 2.* (_information - informationOld) * _expectedLogShrinkage;
 
    // add it to db
    updateSampleDatabase(sampleIdx);

    // replace worst sample
    _liveSamples[sampleIdx]        = _candidates[c];
    _liveLogPriors[sampleIdx]      = _candidateLogPriors[c];
    _liveLogLikelihoods[sampleIdx] = _candidateLogLikelihoods[c];

    // sort rank vector and update constraint
    sortLiveSamplesAscending();

    // select new worst sample
    sampleIdx = _liveSamplesRank[0];

    _lStarOld = _lStar;
    _lStar    = _liveLogLikelihoods[sampleIdx];

  }
  
  if (acceptedBefore == _acceptedSamples) _lastAccepted++;
  else                                    _lastAccepted = 0;
  
  return;
}

void korali::solver::Nested::generateCandidatesFromMCMC() 
{ 
  std::vector<double> zeroMean(_k->_variables.size(), 0.0);
  _multivariateGenerator->_meanVector       = zeroMean;
  _multivariateGenerator->_covarianceMatrix = _covarianceMatrix;
  _multivariateGenerator->updateDistribution();

  for(size_t i = 0; i < _batchSize; i++)
  {
   _multivariateGenerator->getRandomVector(&_candidates[i][0], _k->_variables.size());
   
   size_t cpyIdx = (size_t) (_uniformGenerator->getRandomNumber()*_numberLivePoints);
   for(size_t d = 0; d < _k->_variables.size(); ++d) _candidates[i][d] += _liveSamples[cpyIdx][d];
  }
}

void korali::solver::Nested::generateCandidatesFromBox() 
{
  for(size_t i = 0; i < _batchSize; i++)
  {
   for(size_t d = 0; d < _k->_variables.size(); ++d) 
     _candidates[i][d] = _boxLowerBound[d]+_uniformGenerator->getRandomNumber()*(_boxUpperBound[d]-_boxLowerBound[d]);
  }
}
 
void korali::solver::Nested::generateCandidatesFromEllipse() 
{
  std::vector<double> vec(_k->_variables.size());
  for(size_t i = 0; i < _batchSize; i++)
  {
   double len = 0;
   for(size_t d = 0; d < _k->_variables.size(); ++d) 
   {
     vec[d] = _normalGenerator->getRandomNumber();
     len += vec[d]*vec[d];
   }
   double dim = _k->_variables.size();
   for(size_t d = 0; d < _k->_variables.size(); ++d) 
     vec[d] *= pow(_uniformGenerator->getRandomNumber(),1./dim)/sqrt(len);

   for(size_t k = 0; k < _k->_variables.size(); ++k) 
   {
     _candidates[i][k] = _domainMean[k];
     for(size_t l = k; l < _k->_variables.size(); ++l){
     _candidates[i][k] += _ellipseAxes[k][l]*vec[l];
     }
   }
  }
}

void korali::solver::Nested::updateMeanAndCovariance() 
{
  for (size_t d = 0; d < _k->_variables.size(); d++) _domainMean[d] = 0.0;
    
  double weight1 = 1./((double)_numberLivePoints);
  for (size_t i = 0; i < _numberLivePoints; i++) 
  for (size_t d = 0; d < _k->_variables.size(); d++)
      _domainMean[d] += weight1*_liveSamples[i][d];

  double weight2 = 1./((double)_numberLivePoints-1.);
  for (size_t i = 0; i < _k->_variables.size(); i++){
    for (size_t j = i; j < _k->_variables.size(); ++j){
      double s = 0.;
      for (size_t k = 0; k < _numberLivePoints; ++k) s += (_liveSamples[k][i] - _domainMean[i])*( _liveSamples[k][j]-_domainMean[j] );
          _covarianceMatrix[i*_k->_variables.size() + j] = _covarianceMatrix[j*_k->_variables.size() + i] = _covarianceScaling * weight2 * s;
    }
  }
}


void korali::solver::Nested::updateBox()
{
  for (size_t d = 0; d < _k->_variables.size(); d++) _boxLowerBound[d] = std::numeric_limits<double>::max();
  for (size_t d = 0; d < _k->_variables.size(); d++) _boxUpperBound[d] = std::numeric_limits<double>::lowest();

  for (size_t i = 0; i < _numberLivePoints; i++) 
  for (size_t d = 0; d < _k->_variables.size(); d++)
  {
    _boxLowerBound[d] = std::min(_boxLowerBound[d], _liveSamples[i][d]);
    _boxUpperBound[d] = std::max(_boxUpperBound[d], _liveSamples[i][d]);
  }
}


void korali::solver::Nested::updateEllipse()
{
    for (size_t d = 0; d < _k->_variables.size(); d++) _domainMean[d] = 0.0;
    
    gsl_matrix * cvlup = gsl_matrix_calloc(_k->_variables.size(), _k->_variables.size());
    gsl_matrix * covar = gsl_matrix_calloc(_k->_variables.size(), _k->_variables.size());
 
    double weight1 = 1./((double)_numberLivePoints);
    for (size_t i = 0; i < _numberLivePoints; i++) 
    for (size_t d = 0; d < _k->_variables.size(); d++)
        _domainMean[d] += weight1*_liveSamples[i][d];

    double weight2 = 1./((double)_numberLivePoints-1.);
    for (size_t i = 0; i < _k->_variables.size(); i++){
      for (size_t j = i; j < _k->_variables.size(); ++j){
        double s = 0.0;
        for (size_t k = 0; k < _numberLivePoints; ++k) s += (_liveSamples[k][i] - _domainMean[i])*( _liveSamples[k][j]-_domainMean[j] );
        gsl_matrix_set(cvlup,i,j, weight2*s);
        gsl_matrix_set(cvlup,j,i, weight2*s);
        gsl_matrix_set(covar,j,i, weight2*s);
        gsl_matrix_set(covar,i,j, weight2*s);
      }
    }

    gsl_permutation *p = gsl_permutation_alloc(_k->_variables.size());
    int s;
    int status1 = gsl_linalg_LU_decomp(cvlup, p, &s);

    gsl_matrix *inv = gsl_matrix_alloc(_k->_variables.size(), _k->_variables.size());
    int status2 = gsl_linalg_LU_invert(cvlup, p, inv);

    if((status1 != 0) or (status2 != 0)) gsl_matrix_set_identity(inv);

    gsl_vector * vec  = gsl_vector_calloc(_k->_variables.size());
    gsl_vector * vout = gsl_vector_calloc(_k->_variables.size());
    double res, max = std::numeric_limits<double>::lowest();
    for(size_t i = 0; i < _numberLivePoints; ++i)
    {
        for(size_t d = 0; d < _k->_variables.size(); ++d)
          gsl_vector_set(vec, i, _liveSamples[i][d] - _domainMean[d]);
        
        gsl_blas_dgemv(CblasNoTrans, 1., inv, vec, 0., vout);
        res = 0.;
        gsl_blas_ddot(vec, vout, &res);
        
        if (res > max) max = res;
    }

    gsl_matrix_scale(covar, max);
    int status3 = gsl_linalg_cholesky_decomp1(covar); // LL^T = A
    if (status3 == 1) _k->_logger->logError("Cholesky Decomposition failed during Ellipse update.");
    /* On output the diagonal and lower triangular part of the 
     * input matrix A contain the matrix L, while the upper triangular part 
     * contains the original matrix. */
 
    for(size_t k = 0; k < _k->_variables.size(); k++)
      for(size_t l = 0; l < k+1; l++)
        _ellipseAxes[k][l] = gsl_matrix_get(covar, k, l);

    gsl_vector_free(vec);
    gsl_vector_free(vout);
    gsl_matrix_free(inv);
    gsl_permutation_free(p);
    gsl_matrix_free(cvlup);
    gsl_matrix_free(covar);
}

void korali::solver::Nested::sortLiveSamplesAscending() 
{
  //TODO: speed up
  std::iota (std::begin(_liveSamplesRank), std::end(_liveSamplesRank), 0);
  sort(_liveSamplesRank.begin(), _liveSamplesRank.end(), [this](const size_t & idx1, const size_t & idx2) -> bool { return this->_liveLogLikelihoods[idx1] < this->_liveLogLikelihoods[idx2]; });

}

void korali::solver::Nested::updateSampleDatabase(size_t sampleIdx) 
{
  _databaseEntries++;
  _sampleDatabase.push_back(_liveSamples[sampleIdx]);
  _sampleLogPriorDatabase.push_back(_liveLogPriors[sampleIdx]);
  _sampleLogLikelihoodDatabase.push_back(_liveLogLikelihoods[sampleIdx]);
  _sampleLogWeightDatabase.push_back(_logWeight);
}

void korali::solver::Nested::consumeLiveSamples()
{

  size_t sampleIdx;
  double dLogVol, logEvidenceOld, informationOld, evidenceTerm;
  
  std::vector<double> logvols(_numberLivePoints+1, _logVolume);
  std::vector<double> logdvols(_numberLivePoints);
  std::vector<double> dlvs(_numberLivePoints);

  for(size_t i = 0; i < _numberLivePoints; ++i)
  {
        logvols[i+1] += log(1.-(i+1.)/(_numberLivePoints+1.));
        logdvols[i]  = safeLogMinus(logvols[i], logvols[i+1]);
        dlvs[i]      = logvols[i] - logvols[i+1];
  }
  for(size_t i = 0; i < _numberLivePoints+1; ++i) logdvols[i] += log(0.5);

  for(size_t i = 0; i < _numberLivePoints; ++i)
  {
    sampleIdx = _liveSamplesRank[i];
    
    logEvidenceOld = _logEvidence;
    informationOld = _information;
    
    _lStarOld = _lStar;
    _lStar    = _liveLogLikelihoods[sampleIdx];

    dLogVol = logdvols[i];

    _logVolume   = safeLogMinus(_logVolume, dLogVol);
    _logWeight   = safeLogPlus(_lStar, _lStarOld) + dLogVol;
    _logEvidence = safeLogPlus(_logEvidence, _logWeight);
    
    evidenceTerm = exp(_lStarOld-_logEvidence) * _lStarOld 
        + exp(_lStar-_logEvidence) * _lStar;

    _information  = exp(dLogVol) * evidenceTerm 
       + exp(logEvidenceOld - _logEvidence) * (informationOld + logEvidenceOld) 
       - _logEvidence;
    
    _logEvidenceVar += 2.* (_information - informationOld) * dlvs[i];
    //printf("%f | %f | %f | %f\n", _lStar, dLogVol, _logVolume, _logWeight);
    //printf("%f | %f | %f | %f\n", _logEvidence, evidenceTerm, _information, _logEvidenceVar);
 
    updateSampleDatabase(sampleIdx);
 
  }
  return;

  _numberEffectiveSamples = calcEffectiveSamples();

}

void korali::solver::Nested::generatePosterior() 
{
    double maxLogWtDb = *max_element(std::begin(_sampleLogWeightDatabase), std::end(_sampleLogWeightDatabase));
    
    std::vector<size_t> permutation(_databaseEntries);
    std::iota(std::begin(permutation), std::end(permutation), 0);
    std::random_shuffle(permutation.begin(), permutation.end());

    size_t rndIdx;
    _posteriorSamples.clear();
    
    double k = 1.0;
    double sum = _uniformGenerator->getRandomNumber();
    for(size_t i = 0; i < _databaseEntries; ++i)
    {
        rndIdx = permutation[i];
        sum += exp(_sampleLogWeightDatabase[rndIdx]-maxLogWtDb);
        if(sum > k)
        {
            _posteriorSamples.push_back(_sampleDatabase[rndIdx]);
            k++;
        }
    }
    return; 
}

double korali::solver::Nested::calcEffectiveSamples() const 
{
    if(_databaseEntries < 1) return 0.0;
    
    double wtsum  = std::numeric_limits<double>::lowest();
    double wt2sum = std::numeric_limits<double>::lowest();

    for(size_t i = 0; i < _databaseEntries; ++i)
    {
        wtsum  = safeLogPlus(wtsum, _sampleLogWeightDatabase[i]);
        wt2sum = safeLogPlus(wt2sum, 2.0*_sampleLogWeightDatabase[i]);
    }

    return exp(2.0*wtsum-wt2sum); 
}

double korali::solver::Nested::safeLogPlus(double logx, double logy) const
{
    if(logx>logy) return logx+log(1.0+exp(logy-logx));
    else          return logy+log(1.0+exp(logx-logy));
}

double korali::solver::Nested::safeLogMinus(double logx, double logy) const
{
    return log(exp(logx-logy) - 1) + logy;
}

void korali::solver::Nested::printGenerationBefore() { return; }

void korali::solver::Nested::printGenerationAfter() 
{ 
  _k->_logger->logInfo("Minimal", "Log Evidence: %.4f (+- %.4f)\n", _logEvidence, sqrt(_logEvidenceVar));
  _k->_logger->logInfo("Minimal", "Accepted Samples: %zu (+%zu) \n", _acceptedSamples, _numberLivePoints);
  _k->_logger->logInfo("Minimal", "Effective Samples: %.2f\n", _numberEffectiveSamples);
  _k->_logger->logInfo("Minimal", "Sampling Efficiency: %.2f%%\n", 100.0*(_acceptedSamples+_numberLivePoints)/((double)_generatedSamples));
  _k->_logger->logInfo("Minimal", "lStar: %.2f\n", _lStar);
  _k->_logger->logInfo("Minimal", "Last Accepted: %zu\n", _lastAccepted);
  _k->_logger->logInfo("Minimal", "Information: %.4f\n", _information);
  _k->_logger->logInfo("Minimal", "Log Volume (shrinkage): %.4f (%.2f%%)\n", _logVolume, 100.*(1.-exp(_logVolume)));
  return; 
}

void korali::solver::Nested::finalize()
{
  if (_k->_currentGeneration <= 1 || (_addLivePoints == false) ) return;
  consumeLiveSamples();
  generatePosterior();
  (*_k)["Results"]["Posterior Samples"] = _posteriorSamples;

  _k->_logger->logInfo("Minimal", "Final Log Evidence: %.4f (+- %.4F)\n", _logEvidence, sqrt(_logEvidenceVar));
  _k->_logger->logInfo("Minimal", "Information: %.4f\n", _information);
  _k->_logger->logInfo("Minimal", "Posterior Samples: %zu\n", _posteriorSamples.size());
  return; 
}
