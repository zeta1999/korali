#include "modules/solver/TMCMC/TMCMC.hpp"
#include "modules/conduit/conduit.hpp"
#include "modules/experiment/experiment.hpp"
#include <numeric>
#include <limits>
#include <chrono>

#include <math.h>
#include <gsl/gsl_cdf.h>
#include <gsl/gsl_randist.h>
#include <gsl/gsl_sort_vector.h>
#include <gsl/gsl_matrix.h>
#include <gsl/gsl_linalg.h>
#include <gsl/gsl_statistics.h>
#include <gsl/gsl_multimin.h>

typedef struct fparam_s {
  const double *loglike;  // likelihood values in current generation
  size_t        Ns;       // population size of current generation
  double        exponent; // annealing exponent of current generation
  double        cov;      // target coefficient of variation
} fparam_t;

void korali::solver::TMCMC::setInitialConfiguration()
{
 knlohmann::json problemConfig = (*_k)["Problem"];
 
 if(_maxChainLength == 0) _k->_logger->logError("Max Chain Length must be greater 0.");
 if(_covarianceScaling <= 0.0) _k->_logger->logError("Covariance Scaling must be larger 0.0 (is %lf).\n", _covarianceScaling);

 if (_perGenerationBurnIn.size() > 0 && _perGenerationBurnIn[0] != 0)
 _k->_logger->logWarning("Normal", "The 0th entry of the Burn In vector is being ignored (corresponding to Generation 0)\n");

 if (_perGenerationBurnIn.size() > 1 && _perGenerationBurnIn[1] != 0)
 _k->_logger->logWarning("Normal", "The 1st entry of the Burn In vector is being ignored (corresponding to Generation 1)\n");

 // Allocating TMCMC memory
 _chainLeadersLogPriors.resize(_populationSize);
 _chainLeadersLogLikelihoods.resize(_populationSize);
 _chainLeaders.resize(_populationSize);
 for(size_t i = 0; i < _populationSize; i++) _chainLeaders[i].resize(_k->_variables.size());

 _meanTheta.resize(_k->_variables.size());
 _covarianceMatrix.resize(_k->_variables.size()*_k->_variables.size());

 _chainCandidatesLogPriors.resize(_populationSize);
 _chainCandidatesLogLikelihoods.resize(_populationSize);
 _chainCandidates.resize(_populationSize);
 for(size_t i = 0; i < _populationSize; i++) _chainCandidates[i].resize(_k->_variables.size());
 
 _chainLengths.resize(_populationSize);
 _currentChainStep.resize(_populationSize);
 _chainPendingEvaluation.resize(_populationSize);
 _chainPendingGradient.resize(_populationSize);


 if (_version == "mTMCMC")
 { 
   bool valid = false;
   if (korali::JsonInterface::isDefined(problemConfig, "['Type']"))
   {
       std::string problemType = problemConfig["Type"];
       if (problemType == "Bayesian/Reference") valid = true;
   }
   if (valid == false) _k->_logger->logError("mTMCMC works only for problems of type 'Bayesian/Reference'\n");

   if (_maxChainLength != 1) _k->_logger->logError("Current version of 'mTMCMC' supports only 'Max Chain Length' of 1 (BASIS).");
   if (_stepSize < 0.0) _k->_logger->logError("Step Size lower than 0.0 (is %lf)\n", _stepSize);
   if (_domainExtensionFactor < 0.0) _k->_logger->logError("Domain Extension Factor lower than 0.0 (is %lf)\n", _domainExtensionFactor);

   _chainCandidatesErrors.resize(_populationSize, -1);
   _chainLeadersErrors.resize(_populationSize, -1);
   _sampleErrorDatabase.resize(_populationSize, -1);
   _chainCandidatesGradients.resize(_populationSize);
   for(size_t i = 0; i < _populationSize; i++) _chainCandidatesGradients[i].resize(_k->_variables.size());
   _chainLeadersGradients.resize(_populationSize);
   for(size_t i = 0; i < _populationSize; i++) _chainLeadersGradients[i].resize(_k->_variables.size());
   _sampleGradientDatabase.resize(_populationSize);
   for(size_t i = 0; i < _populationSize; i++) _sampleGradientDatabase[i].resize(_k->_variables.size());
   _chainCandidatesCovariance.resize(_populationSize);
   for(size_t i = 0; i < _populationSize; i++) _chainCandidatesCovariance[i].resize(_k->_variables.size()*_k->_variables.size());
   _chainLeadersCovariance.resize(_populationSize);
   for(size_t i = 0; i < _populationSize; i++) _chainLeadersCovariance[i].resize(_k->_variables.size()*_k->_variables.size());
   _sampleCovariancesDatabase.resize(_populationSize);
   for(size_t i = 0; i < _populationSize; i++) _sampleCovariancesDatabase[i].resize(_k->_variables.size());

   _upperExtendedBoundaries.resize(_k->_variables.size());
   _lowerExtendedBoundaries.resize(_k->_variables.size());

   for(size_t d = 0; d < _k->_variables.size(); ++d)
   {
     if (_k->_distributions[_k->_variables[d]->_distributionIndex]->_type != "Univariate/Uniform") _k->_logger->logError("Only 'Univariate/Uniform' priors allowed (is %s).\n", _k->_distributions[_k->_variables[d]->_distributionIndex]->_type.c_str());
     double width = dynamic_cast<korali::distribution::univariate::Uniform*>(_k->_distributions[_k->_variables[d]->_distributionIndex])->_maximum - dynamic_cast<korali::distribution::univariate::Uniform*>(_k->_distributions[_k->_variables[d]->_distributionIndex])->_minimum;
        _upperExtendedBoundaries[d] = dynamic_cast<korali::distribution::univariate::Uniform*>(_k->_distributions[_k->_variables[d]->_distributionIndex])->_maximum+width*_domainExtensionFactor;
        _lowerExtendedBoundaries[d] = dynamic_cast<korali::distribution::univariate::Uniform*>(_k->_distributions[_k->_variables[d]->_distributionIndex])->_minimum-width*_domainExtensionFactor;
     }
     
 }

 // Init
 _annealingExponent        = 0.0;
 _logEvidence              = 0.0;
 _coefficientOfVariation   = 0.0;
 _numCovarianceCorrections = 0;
 _chainCount               = _populationSize;

 // Initializing Chain Length first Generation
 std::fill( std::begin(_chainLengths), std::end(_chainLengths), 1);
}

void korali::solver::TMCMC::runGeneration()
{
  if (_k->_currentGeneration == 1) setInitialConfiguration();

  prepareGeneration();
  std::vector<korali::Sample> samples(_chainCount);

  while (_finishedChainsCount < _chainCount)
  {
    for (size_t c = 0; c < _chainCount; c++)
    {
     if (_currentChainStep[c] < _chainLengths[c] + _currentBurnIn)
     if (_chainPendingEvaluation[c] == false)
     {
       _chainPendingEvaluation[c] = true;
       samples[c]["Module"]     = "Problem";
       samples[c]["Operation"]  = "Evaluate";
       samples[c]["Parameters"] =  _chainCandidates[c];
       samples[c]["Sample Id"]  = c;
       _currentChainStep[c]++;
       _modelEvaluationCount++;
       _conduit->start(samples[c]);
      }
    }
    
    size_t finishedId = _conduit->waitAny(samples);
    _chainPendingEvaluation[finishedId] = false;
    
    _chainCandidatesLogLikelihoods[finishedId] = samples[finishedId]["logLikelihood"];
    _chainCandidatesLogPriors[finishedId]      = samples[finishedId]["logPrior"];
 
    if(_version == "TMCMC") processCandidate(finishedId);
    if(_currentChainStep[finishedId] == _chainLengths[finishedId] + _currentBurnIn) _finishedChainsCount++;
  }

  if(_version == "mTMCMC")
  {
    if(_k->_currentGeneration > 1) { calculateGradients(samples); calculateProposals(samples); }
    for(size_t sampleId = 0; sampleId < _populationSize; ++sampleId) processCandidate(sampleId);
  }

  processGeneration();

  (*_k)["Results"]["Sample Database"] = _sampleDatabase;
}

void korali::solver::TMCMC::prepareGeneration()
{
  setBurnIn();

  _acceptedSamplesCount = 0;
  _finishedChainsCount  = 0;

  _sampleLogLikelihoodDatabase.clear();
  _sampleLogPriorDatabase.clear();
  _sampleDatabase.clear();

  if(_version =="mTMCMC")
  {
    _sampleErrorDatabase.clear();
    _sampleGradientDatabase.clear();
    _sampleCovariancesDatabase.clear();
    if(_k->_currentGeneration > 1) std::fill(_chainCandidatesErrors.begin(), _chainCandidatesErrors.end(), 0);
    else                           std::fill(_chainCandidatesErrors.begin(), _chainCandidatesErrors.end(), -1);
  }
 
  std::fill(_currentChainStep.begin(), _currentChainStep.end(), 0);
  std::fill(_chainPendingEvaluation.begin(), _chainPendingEvaluation.end(), false);

  std::vector<double> zeroMean(_k->_variables.size(), 0.0);
  _multivariateGenerator->_meanVector = zeroMean;
  _multivariateGenerator->_covarianceMatrix = _covarianceMatrix;
  _multivariateGenerator->updateDistribution();

  for(size_t i = 0; i < _populationSize; i++)
  {
    if( _k->_currentGeneration == 1)
    {
     for (size_t d = 0; d < _k->_variables.size(); d++)
       _chainCandidates[i][d] = _k->_distributions[_k->_variables[d]->_distributionIndex]->getRandomNumber();
    }
    else
    {
      generateCandidate(i);
    }
  }
}

void korali::solver::TMCMC::processCandidate(const size_t sampleId)
{
  double P = calculateAcceptanceProbability(sampleId);
  double U = _uniformGenerator->getRandomNumber();

  if( P > U || _k->_currentGeneration == 1 )
  {
    _chainLeaders[sampleId]               = _chainCandidates[sampleId];
    _chainLeadersLogPriors[sampleId]      = _chainCandidatesLogPriors[sampleId];
    _chainLeadersLogLikelihoods[sampleId] = _chainCandidatesLogLikelihoods[sampleId];
    if(_version == "mTMCMC")
    {
      _chainLeadersErrors[sampleId]     = _chainCandidatesErrors[sampleId];
      _chainLeadersGradients[sampleId]  = _chainCandidatesGradients[sampleId];
      _chainLeadersCovariance[sampleId] = _chainCandidatesCovariance[sampleId];
    }
    
    if( _currentChainStep[sampleId] > _currentBurnIn ) _acceptedSamplesCount++;
    generateCandidate(sampleId);
  }
    
  if(_currentChainStep[sampleId] > _currentBurnIn) updateDatabase(sampleId);

}


void korali::solver::TMCMC::processGeneration()
{

  // Compute annealing exponent for next generation
  double fmin = 0, xmin = 0;
  minSearch( _sampleLogLikelihoodDatabase.data(), _populationSize, _annealingExponent, _targetCoefficientOfVariation, xmin, fmin );

  _previousAnnealingExponent = _annealingExponent;

  if( xmin > _previousAnnealingExponent + _maxAnnealingExponentUpdate )
  {
    _k->_logger->logWarning("Normal", "Annealing Step larger than Max Rho Update, updating Annealing Exponent by %f (Max Rho Update). \n", _maxAnnealingExponentUpdate);
    _annealingExponent      = _previousAnnealingExponent + _maxAnnealingExponentUpdate;
    _coefficientOfVariation = sqrt(tmcmc_objlogp(_annealingExponent, _sampleLogLikelihoodDatabase.data(), _populationSize, _previousAnnealingExponent, _targetCoefficientOfVariation)) + _targetCoefficientOfVariation;
  }
  else if( xmin < 1.0 && xmin < _previousAnnealingExponent + _minAnnealingExponentUpdate )
  {
    _k->_logger->logWarning("Normal", "Annealing Step smaller than Min Rho Update, updating Annealing Exponent by %f (Min Rho Update). \n", _minAnnealingExponentUpdate);
    _annealingExponent      = _previousAnnealingExponent + _minAnnealingExponentUpdate;
    _coefficientOfVariation = sqrt(tmcmc_objlogp(_annealingExponent, &_sampleLogLikelihoodDatabase[0], _populationSize, _previousAnnealingExponent, _targetCoefficientOfVariation)) + _targetCoefficientOfVariation;
  }
  else
  { 
    _annealingExponent      = xmin;
    _coefficientOfVariation = sqrt(fmin) + _targetCoefficientOfVariation;
  }

  /* Compute weights and normalize*/
  std::vector<double>  log_weight(_populationSize);
  std::vector<double>  weight(_populationSize);
  for (size_t i = 0; i < _populationSize; i++) log_weight[i] = _sampleLogLikelihoodDatabase[i]*(_annealingExponent-_previousAnnealingExponent);

  const double loglikemax = gsl_stats_max(log_weight.data(), 1, _populationSize);
  for( size_t i = 0; i < _populationSize; i++ )  weight[i] = exp( log_weight[i] - loglikemax );

  double sum_weight = std::accumulate( weight.begin(), weight.end(), 0.0 );

  _logEvidence += log(sum_weight) + loglikemax - log(_populationSize);

  for (size_t i = 0; i < _populationSize; i++)  weight[i] = weight[i] / sum_weight;

  /* Update mean and covariance */
  for (size_t i = 0; i < _k->_variables.size(); i++){
    _meanTheta[i] = 0;
    for (size_t j = 0; j < _populationSize; j++) _meanTheta[i] += _sampleDatabase[j][i]*weight[j];
  }

  for (size_t i = 0; i < _k->_variables.size(); i++){
    for (size_t j = i; j < _k->_variables.size(); ++j){
      double s = 0.0;
      for (size_t k = 0; k < _populationSize; ++k)
        s += weight[k]*( _sampleDatabase[k][i] - _meanTheta[i])*( _sampleDatabase[k][j]-_meanTheta[j] );
      _covarianceMatrix[i*_k->_variables.size() + j] = _covarianceMatrix[j*_k->_variables.size() + i] = _covarianceScaling * s;
    }
  }

  gsl_matrix_view sigma = gsl_matrix_view_array( &_covarianceMatrix[0], _k->_variables.size(), _k->_variables.size() );
  gsl_linalg_cholesky_decomp( &sigma.matrix );

  /* Sample candidate selections based on database entries */
  std::vector<unsigned int> numselections(_populationSize);
  _multinomialGenerator->getSelections( weight, numselections, _populationSize);

  /* Resampling - Init new chains */
  std::fill( std::begin(_chainLengths), std::end(_chainLengths), 0);

  size_t leaderChainLen;
  size_t zeroCount = 0;
  size_t leaderId = 0;
  for (size_t i = 0; i < _populationSize; i++)
  {
    if (numselections[i] == 0) zeroCount++;
    while (numselections[i] > 0)
    {
      _chainLeaders[leaderId]               = _sampleDatabase[i];
      _chainLeadersLogPriors[leaderId]      = _sampleLogPriorDatabase[i];
      _chainLeadersLogLikelihoods[leaderId] = _sampleLogLikelihoodDatabase[i];
      if(_version == "mTMCMC")
      {
        _chainLeadersErrors[leaderId]     = _sampleErrorDatabase[i];
        _chainLeadersGradients[leaderId]  = _sampleGradientDatabase[i];
        _chainLeadersCovariance[leaderId] = _sampleCovariancesDatabase[i];
      }

      if (numselections[i] > _maxChainLength){
       /* uniform splitting of chains */
       size_t rest = (numselections[i] % _maxChainLength != 0);
       leaderChainLen = _maxChainLength - rest;
      }
      else
      {
        leaderChainLen = numselections[i];
      }
      _chainLengths[leaderId] = leaderChainLen;
      numselections[i] -= leaderChainLen;
      leaderId++;
    }
  }

  /* Anneal gradients and proposal */
  if(_version == "mTMCMC" && _previousAnnealingExponent > 0.0)
  for(size_t i = 0; i < _populationSize; ++i)
  {
    if(_chainLeadersErrors[i] != 0) continue;
    gsl_vector_view gradLeader = gsl_vector_view_array(&_chainLeadersGradients[i][0], _k->_variables.size());
    gsl_vector_scale(&gradLeader.vector, _annealingExponent/_previousAnnealingExponent);
 
    gsl_matrix_view covLeader = gsl_matrix_view_array(&_chainLeadersCovariance[i][0], _k->_variables.size(), _k->_variables.size());
    gsl_matrix_scale(&covLeader.matrix, _annealingExponent/_previousAnnealingExponent);
  }

  /* Update acceptance statistics */
  size_t uniqueSelections  = _populationSize - zeroCount;
  _proposalsAcceptanceRate = (1.0*_acceptedSamplesCount)/_populationSize;
  _selectionAcceptanceRate = (1.0*uniqueSelections)/_populationSize;

  _chainCount = leaderId;
}
 
void korali::solver::TMCMC::calculateGradients(std::vector<korali::Sample>& samples)
{ 
 for (size_t c = 0; c < _chainCount; ++c)
 {
      samples[c]["Module"]     = "Problem";
      samples[c]["Operation"]  = "Evaluate Gradient";
      _conduit->start(samples[c]);
 }

 for(size_t c = 0; c < _chainCount; c++)
 {
   size_t finishedId = _conduit->waitAny(samples);
   for(size_t d = 0; d < _k->_variables.size(); ++d) _chainCandidatesGradients[finishedId][d] = samples[finishedId]["logLikelihood Gradient"][d];
   
   // anneal
   for(size_t d = 0; d < _k->_variables.size(); ++d) _chainCandidatesGradients[finishedId][d] *= _annealingExponent;
 }
}

void korali::solver::TMCMC::calculateProposals(std::vector<korali::Sample>& samples) 
{ 
  for (size_t c = 0; c < _chainCount; ++c)
  {
    samples[c]["Module"]     = "Problem";
    samples[c]["Operation"]  = "Evaluate Fisher Information";
    _conduit->start(samples[c]);
  }
 
  int status;
  size_t Nth = _k->_variables.size();
  gsl_vector* ccpy0  = gsl_vector_alloc(Nth);
  gsl_vector* ccpy1  = gsl_vector_alloc(Nth);
 
  for(size_t c = 0; c < _chainCount; c++)
  {
    size_t finishedId = _conduit->waitAny(samples);
    std::fill( _chainCandidatesCovariance[finishedId].begin(), _chainCandidatesCovariance[finishedId].end(), 0.0);
    
    std::vector<double> FIM = samples[finishedId]["Fisher Information"];
    gsl_matrix_view FIMview = gsl_matrix_view_array(&FIM[0], Nth, Nth);

    // scale FIM
    gsl_matrix_scale(&FIMview.matrix, _annealingExponent/_stepSize);
 
    // invert FIM
    gsl_permutation *perm = gsl_permutation_alloc(Nth);
   
    int s;
    status = gsl_linalg_LU_decomp(&FIMview.matrix, perm, &s);
    if (status != GSL_SUCCESS) { _chainCandidatesErrors[finishedId] = 1; gsl_permutation_free(perm); continue; }
    
    gsl_matrix *FIMinv = gsl_matrix_alloc(Nth, Nth);
    status = gsl_linalg_LU_invert(&FIMview.matrix, perm, FIMinv);
    gsl_permutation_free(perm);
    if (status != GSL_SUCCESS) { _chainCandidatesErrors[finishedId] = 2; gsl_matrix_free(FIMinv); continue; }
  
    // eigenvalue decomposition
    gsl_vector* Evals = gsl_vector_alloc(Nth);
    gsl_matrix* Evecs = gsl_matrix_alloc(Nth,Nth);
    gsl_eigen_symmv_workspace* work = gsl_eigen_symmv_alloc(Nth);
    status = gsl_eigen_symmv(FIMinv, Evals, Evecs, work);
    gsl_eigen_symmv_free(work);
    
    double minEval = gsl_vector_min(Evals);
    if (status != GSL_SUCCESS) { _chainCandidatesErrors[finishedId] = 3; gsl_matrix_free(FIMinv); gsl_vector_free(Evals); gsl_matrix_free(Evecs); continue; }
 
    if (minEval <= 0.0) { _chainCandidatesErrors[finishedId] = 4; gsl_matrix_free(FIMinv); gsl_vector_free(Evals); gsl_matrix_free(Evecs); continue; }


    // correction
    double correction = false;
    double distToUpper, distToLower;
    double len, chi2 = gsl_cdf_chisq_Pinv( 0.95, Nth);
    
    gsl_vector_const_view candidate = gsl_vector_const_view_array(&_chainCandidates[finishedId][0], Nth);
    
    for(size_t d = 0; d < Nth; ++d)
    {
        gsl_vector_memcpy(ccpy0, &candidate.vector);
        gsl_vector_memcpy(ccpy1, &candidate.vector);
        
        double scale = sqrt(chi2*gsl_vector_get(Evals,d));
        double scaleBefore = scale;
        
        gsl_vector_const_view evec = gsl_matrix_const_column(Evecs,d);
        gsl_blas_daxpy(+1.0*scale, &evec.vector, ccpy0);
        gsl_blas_daxpy(-1.0*scale, &evec.vector, ccpy1);

        // measure overshoot & undershoot in all dims
        for(size_t e = 0; e < Nth; ++e)
        {
            distToUpper = _upperExtendedBoundaries[e] - _chainCandidates[finishedId][e];
            distToLower = _chainCandidates[finishedId][e] - _lowerExtendedBoundaries[e];
           
            len = gsl_vector_get(ccpy0,e) - _upperExtendedBoundaries[e];
            if(len > 0.) scale = std::min(scale, std::abs(1.0/gsl_vector_get(&evec.vector, e)*distToUpper));
           
            len = _lowerExtendedBoundaries[e]-gsl_vector_get(ccpy0,e);
            if(len > 0.) scale = std::min(scale, std::abs(1.0/gsl_vector_get(&evec.vector, e)*distToLower));
  
            len = gsl_vector_get(ccpy1,e) - _upperExtendedBoundaries[e];
            if(len > 0.) scale = std::min(scale, std::abs(1.0/gsl_vector_get(&evec.vector, e)*distToUpper));
            
            len = _lowerExtendedBoundaries[e]-gsl_vector_get(ccpy1,e);
            if(len > 0.) scale = std::min(scale, std::abs(1.0/gsl_vector_get(&evec.vector, e)*distToLower));
        }
        // scale evals
        gsl_vector_set(Evals, d,  scale*scale/chi2);
        if(scaleBefore != scale) correction = true;
    }

    if (correction) _numCovarianceCorrections++;

    
    // construct & store
    for(size_t d = 0; d < Nth; ++d)
    {
        gsl_vector_view evec = gsl_matrix_column(Evecs,d);
        gsl_vector_scale(&evec.vector, sqrt(gsl_vector_get(Evals,d)));
    }
    
    gsl_matrix_view candidatecov = gsl_matrix_view_array(&_chainCandidatesCovariance[finishedId][0], Nth, Nth);
    gsl_blas_dgemm(CblasNoTrans, CblasTrans, 1.0, Evecs, Evecs, 0.0, &candidatecov.matrix);

    gsl_matrix_free(Evecs);
    gsl_vector_free(Evals);
    gsl_matrix_free(FIMinv);
  } 
   
  gsl_vector_free(ccpy0);
  gsl_vector_free(ccpy1);
  
}
 
void korali::solver::TMCMC::generateCandidate(const size_t sampleId) 
{ 
    if(_version == "TMCMC")
    {
      _multivariateGenerator->getRandomVector(&_chainCandidates[sampleId][0],  _k->_variables.size());
      for (size_t d = 0; d < _k->_variables.size(); d++) _chainCandidates[sampleId][d] += _chainLeaders[sampleId][d];
    }
    else /* "mTMCMC" */
    {
      // TODO: refine error treatment granularity
      if( _chainLeadersErrors[sampleId] == 0 )
      {
        std::vector<double> zeroMean(_k->_variables.size(), 0.0);
        _multivariateGenerator->_meanVector       = _chainLeaders[sampleId];
        _multivariateGenerator->_covarianceMatrix = _chainLeadersCovariance[sampleId]; // check scaling
        _multivariateGenerator->updateDistribution();
        _multivariateGenerator->getRandomVector(&_chainCandidates[sampleId][0], _k->_variables.size());

        gsl_vector_view candidate  = gsl_vector_view_array(&_chainCandidates[sampleId][0], _k->_variables.size());
        gsl_vector_const_view leaderGrad = gsl_vector_const_view_array(&_chainLeadersGradients[sampleId][0], _k->_variables.size());
        gsl_matrix_const_view leaderCov  = gsl_matrix_const_view_array(&_chainLeadersCovariance[sampleId][0], _k->_variables.size(),_k->_variables.size());
        gsl_blas_dgemv(CblasNoTrans, 0.5, &leaderCov.matrix, &leaderGrad.vector, 1.0, &candidate.vector);

      }
      else /* error */                       
      {
        _multivariateGenerator->_meanVector       = _chainLeaders[sampleId];
        _multivariateGenerator->_covarianceMatrix = _covarianceMatrix;
        _multivariateGenerator->updateDistribution();
        _multivariateGenerator->getRandomVector(&_chainCandidates[sampleId][0], _k->_variables.size());
      }
    
    }
}

void korali::solver::TMCMC::updateDatabase(const size_t sampleId)
{
  
  _sampleDatabase.push_back(_chainLeaders[sampleId]);
  _sampleLogPriorDatabase.push_back(_chainLeadersLogPriors[sampleId]);
  _sampleLogLikelihoodDatabase.push_back(_chainLeadersLogLikelihoods[sampleId]);

  if(_version == "mTMCMC")
  {
    _sampleErrorDatabase.push_back(_chainLeadersErrors[sampleId]);
    _sampleGradientDatabase.push_back(_chainLeadersGradients[sampleId]);
    _sampleCovariancesDatabase.push_back(_chainLeadersCovariance[sampleId]);
  }
 

}


double korali::solver::TMCMC::calculateAcceptanceProbability(const size_t sampleId) 
{ 
    double P = 0.0;
    if( std::isfinite(_chainCandidatesLogLikelihoods[sampleId]) && std::isfinite(_chainCandidatesLogPriors[sampleId]) )
    if(_version == "TMCMC")
    {
        P = exp(  (_chainCandidatesLogLikelihoods[sampleId]-_chainLeadersLogLikelihoods[sampleId])*_annealingExponent
            + (_chainCandidatesLogPriors[sampleId]-_chainLeadersLogPriors[sampleId]) );
    }
    else /* mTMCMC */
    {
      // TODO: refine error treatment granularity
      if((_chainLeadersErrors[sampleId] == 0) && (_chainCandidatesErrors[sampleId] == 0))
      {
        gsl_vector* meanLeader    = gsl_vector_alloc(_k->_variables.size());
        gsl_vector* meanCandidate = gsl_vector_alloc(_k->_variables.size());
            
        gsl_vector_const_view gradLeader    = gsl_vector_const_view_array(&_chainLeadersGradients[sampleId][0], _k->_variables.size());
        gsl_vector_const_view gradCandidate = gsl_vector_const_view_array(&_chainCandidatesGradients[sampleId][0], _k->_variables.size());
            
        gsl_matrix_const_view covLeader = gsl_matrix_const_view_array(&_chainLeadersCovariance[sampleId][0], _k->_variables.size(), _k->_variables.size());
            
        gsl_blas_dgemv(CblasNoTrans, 0.5, &covLeader.matrix, &gradLeader.vector, 1.0, meanLeader);
        gsl_blas_dgemv(CblasNoTrans, 0.5, &covLeader.matrix, &gradCandidate.vector, 1.0, meanCandidate);
  
        gsl_vector_const_view leader    = gsl_vector_const_view_array(&_chainLeaders[sampleId][0], _k->_variables.size());
        gsl_vector_const_view candidate = gsl_vector_const_view_array(&_chainCandidates[sampleId][0], _k->_variables.size());
    
        gsl_matrix* cholCovLeader = gsl_matrix_alloc(_k->_variables.size(), _k->_variables.size());
        gsl_matrix_memcpy(cholCovLeader, &covLeader.matrix);
        int status = gsl_linalg_cholesky_decomp1(cholCovLeader);
    
        gsl_vector* work = gsl_vector_alloc(_k->_variables.size());
        
        double logpCandidate, logpLeader;
        gsl_ran_multivariate_gaussian_log_pdf(&candidate.vector, meanLeader, cholCovLeader, &logpCandidate, work);
        gsl_ran_multivariate_gaussian_log_pdf(&leader.vector, meanCandidate, cholCovLeader, &logpLeader, work);

        gsl_vector_free(work);
        gsl_matrix_free(cholCovLeader);
        gsl_vector_free(meanLeader);
        gsl_vector_free(meanCandidate);

        P = exp( (_chainCandidatesLogLikelihoods[sampleId]-_chainLeadersLogLikelihoods[sampleId])*_annealingExponent + (logpLeader - logpCandidate) + (_chainCandidatesLogPriors[sampleId]-_chainLeadersLogPriors[sampleId]) );
     }
     else /* error */
     {
       P = exp(  (_chainCandidatesLogLikelihoods[sampleId]-_chainLeadersLogLikelihoods[sampleId])*_annealingExponent
         + (_chainCandidatesLogPriors[sampleId]-_chainLeadersLogPriors[sampleId]) );
     }
   }
   return P; 
}

double korali::solver::TMCMC::tmcmc_objlogp(double x, const double *loglike, size_t Ns, double exponent, double targetCOV )
{
  // x: proposed exponent
  std::vector<double> weight(Ns);
  const double loglike_max = gsl_stats_max(loglike, 1, Ns);

  for(size_t i = 0; i <Ns; i++)  weight[i] = exp( (loglike[i]-loglike_max) * (x-exponent) );

  double sum_weight = std::accumulate( weight.begin(), weight.end(), 0.0 );

  for(size_t i = 0; i < Ns; i++) weight[i] = weight[i] / sum_weight;

  double mean = gsl_stats_mean( weight.data(), 1, Ns);
  double std  = gsl_stats_sd_m( weight.data(), 1, Ns, mean);
  double cov2   = (std/mean) - targetCOV;
  cov2 *= cov2;

  if( isfinite(cov2)==false )
    return korali::Lowest;
  else
    return cov2;
}


double korali::solver::TMCMC::objLog(const gsl_vector *v, void *param)
{
  double x = gsl_vector_get(v, 0);
  fparam_t *fp = (fparam_t *) param;
  return korali::solver::TMCMC::tmcmc_objlogp(x, fp->loglike, fp->Ns, fp->exponent, fp->cov);
}


void korali::solver::TMCMC::minSearch(double const *loglike, size_t Ns, double exponent, double objCov, double& xmin, double& fmin)
{
  // Minimizer Options
  const size_t MaxIter = 1000;  /* Max number of search iterations */
  const double Tol     = 1e-12; /* Tolerance for root finding */
  const double Step    = 1e-8;  /* Search stepsize */

  const gsl_multimin_fminimizer_type *T;
  gsl_multimin_fminimizer *s = NULL;
  gsl_vector *ss, *x;
  gsl_multimin_function minex_func;

  size_t iter = 0;
  int status;
  double size;

  fparam_t fp;
  fp.loglike  = loglike;
  fp.Ns  = Ns;
  fp.exponent  = exponent;
  fp.cov = objCov;

  x = gsl_vector_alloc(1);
  gsl_vector_set( x, 0, exponent );

  ss = gsl_vector_alloc(1);
  gsl_vector_set_all( ss, Step );

  minex_func.n      = 1;
  minex_func.f      = objLog;
  minex_func.params = &fp;

  T = gsl_multimin_fminimizer_nmsimplex;
  s = gsl_multimin_fminimizer_alloc (T, 1);
  gsl_multimin_fminimizer_set(s, &minex_func, x, ss);

  fmin = 0;
  xmin = 0.0;

  do{
    iter++;
    status = gsl_multimin_fminimizer_iterate(s);
    size   = gsl_multimin_fminimizer_size(s);
    status = gsl_multimin_test_size(size, Tol);
  } while( status == GSL_CONTINUE && iter < MaxIter );

  if(status == GSL_SUCCESS && s->fval >  Tol) _k->_logger->logWarning("Normal", "Min Search converged but did not find minimum. \n");
  if(status != GSL_SUCCESS && s->fval <= Tol) _k->_logger->logWarning("Normal", "Min Search did not converge but minimum found\n");
  if(status != GSL_SUCCESS && s->fval >  Tol) _k->_logger->logWarning("Normal", "Min Search did not converge and did not find minimum\n");
  if(iter >= MaxIter) _k->_logger->logWarning("Normal", "Min Search MaxIter (%zu) reached\n", MaxIter);

  if( s->fval <= Tol ){
    fmin = s->fval;
    xmin = gsl_vector_get( s->x, 0 );
  }

  if (xmin >= 1.0) {
    fmin = tmcmc_objlogp(1.0, loglike, Ns, exponent, objCov);
    xmin = 1.0;
  }

  gsl_vector_free(x);
  gsl_vector_free(ss);
  gsl_multimin_fminimizer_free (s);
}


void korali::solver::TMCMC::setBurnIn()
{
  if( _k->_currentGeneration==1 )
    _currentBurnIn = 0;
  else if (_k->_currentGeneration < _perGenerationBurnIn.size())
    _currentBurnIn = _perGenerationBurnIn[_k->_currentGeneration];
  else
    _currentBurnIn = _defaultBurnIn;
}


void korali::solver::TMCMC::finalize()
{

}


void korali::solver::TMCMC::printGenerationBefore()
{
  _k->_logger->logInfo("Minimal", "Annealing Exponent:          %.3e.\n", _annealingExponent);
}


void korali::solver::TMCMC::printGenerationAfter()
{
  _k->_logger->logInfo("Minimal", "Acceptance Rate (proposals / selections): (%.2f%% / %.2f%%)\n", 100*_proposalsAcceptanceRate, 100*_selectionAcceptanceRate);
  _k->_logger->logInfo("Normal", "Coefficient of Variation: %.2f%%\n", 100.0*_coefficientOfVariation);
  _k->_logger->logInfo("Normal", "logEvidence: %.3f\n", _logEvidence);

  _k->_logger->logInfo("Detailed", "Sample Mean:\n");
  for (size_t i = 0; i < _k->_variables.size(); i++) _k->_logger->logData("Detailed", " %s = %+6.3e\n", _k->_variables[i]->_name.c_str(), _meanTheta[i]);
  _k->_logger->logInfo("Detailed", "Sample Covariance:\n");
  if(_version == "mTMCMC")
  _k->_logger->logInfo("Detailed", "Number Of Covatiance Corrections: %zu\n", _numCovarianceCorrections);


  for (size_t i = 0; i < _k->_variables.size(); i++){
    _k->_logger->logData("Detailed", "   | ");
    for (size_t j = 0; j < _k->_variables.size(); j++)
      if(j <= i)  _k->_logger->logData("Detailed", "%+6.3e  ",_covarianceMatrix[i*_k->_variables.size()+j]);
    else
      _k->_logger->logData("Detailed", "     -      ");
    _k->_logger->logData("Detailed", " |\n");
  }
}
