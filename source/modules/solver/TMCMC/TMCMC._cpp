#include "modules/conduit/conduit.hpp"
#include "modules/experiment/experiment.hpp"
#include "modules/solver/TMCMC/TMCMC.hpp"
#include <chrono>
#include <limits>
#include <numeric>

#include <gsl/gsl_cdf.h>
#include <gsl/gsl_linalg.h>
#include <gsl/gsl_matrix.h>
#include <gsl/gsl_multimin.h>
#include <gsl/gsl_randist.h>
#include <gsl/gsl_sort_vector.h>
#include <gsl/gsl_statistics.h>
#include <math.h>

/**
  * @brief Struct for TMCMC optimization operations
 */
typedef struct fparam_s
{
  /**
  * @brief Likelihood values in current generation
 */
  const double *loglike;

  /**
    * @brief Population size of current generation
   */
  size_t Ns;

  /**
    * @brief Annealing exponent of current generation
   */
  double exponent;

  /**
    * @brief Target coefficient of variation
   */
  double cov;
} fparam_t;

void korali::solver::TMCMC::setInitialConfiguration()
{
  knlohmann::json problemConfig = (*_k)["Problem"];

  if (_maxChainLength == 0) korali::Logger::logError("Max Chain Length must be greater 0.");
  if (_covarianceScaling <= 0.0) korali::Logger::logError("Covariance Scaling must be larger 0.0 (is %lf).\n", _covarianceScaling);

  if (_perGenerationBurnIn.size() > 0 && _perGenerationBurnIn[0] != 0)
    _k->_logger->logWarning("Normal", "The 0th entry of the Burn In vector is being ignored (corresponding to Generation 0)\n");

  if (_perGenerationBurnIn.size() > 1 && _perGenerationBurnIn[1] != 0)
    _k->_logger->logWarning("Normal", "The 1st entry of the Burn In vector is being ignored (corresponding to Generation 1)\n");

  // Allocating TMCMC memory
  _chainLeadersLogPriors.resize(_populationSize);
  _chainLeadersLogLikelihoods.resize(_populationSize);
  _chainLeaders.resize(_populationSize);
  for (size_t i = 0; i < _populationSize; i++) _chainLeaders[i].resize(_k->_variables.size());

  _meanTheta.resize(_k->_variables.size());
  _covarianceMatrix.resize(_k->_variables.size() * _k->_variables.size());

  _chainCandidatesLogPriors.resize(_populationSize);
  _chainCandidatesLogLikelihoods.resize(_populationSize);
  _chainCandidates.resize(_populationSize);
  for (size_t i = 0; i < _populationSize; i++) _chainCandidates[i].resize(_k->_variables.size());

  _chainLengths.resize(_populationSize);
  _currentChainStep.resize(_populationSize);
  _chainPendingEvaluation.resize(_populationSize);
  _chainPendingGradient.resize(_populationSize);

  if (_version == "mTMCMC")
  {
    bool valid = false;
    if (korali::JsonInterface::isDefined(problemConfig, "['Type']"))
    {
      std::string problemType = problemConfig["Type"];
      if (problemType == "Bayesian/Reference") valid = true;
    }
    if (valid == false) korali::Logger::logError("mTMCMC works only for problems of type 'Bayesian/Reference'\n");

    if (_maxChainLength != 1) korali::Logger::logError("Current version of 'mTMCMC' supports only 'Max Chain Length' of 1 (BASIS).");
    if (_stepSize < 0.0) korali::Logger::logError("Step Size lower than 0.0 (is %lf)\n", _stepSize);
    if (_domainExtensionFactor < 0.0) korali::Logger::logError("Domain Extension Factor lower than 0.0 (is %lf)\n", _domainExtensionFactor);
    if (_targetAcceptanceRate <= 0.0 || _targetAcceptanceRate > 1.0) korali::Logger::logError("Target Acceptance Rate must be in (0,1), is %lf.", _targetAcceptanceRate);

    _chainCandidatesErrors.resize(_populationSize, -1);
    _chainLeadersErrors.resize(_populationSize, -1);
    _sampleErrorDatabase.resize(_populationSize, -1);
    _chainCandidatesGradients.resize(_populationSize);
    for (size_t i = 0; i < _populationSize; i++) _chainCandidatesGradients[i].resize(_k->_variables.size());
    _chainLeadersGradients.resize(_populationSize);
    for (size_t i = 0; i < _populationSize; i++) _chainLeadersGradients[i].resize(_k->_variables.size());
    _sampleGradientDatabase.resize(_populationSize);
    for (size_t i = 0; i < _populationSize; i++) _sampleGradientDatabase[i].resize(_k->_variables.size());
    _chainCandidatesCovariance.resize(_populationSize);
    for (size_t i = 0; i < _populationSize; i++) _chainCandidatesCovariance[i].resize(_k->_variables.size() * _k->_variables.size());
    _chainLeadersCovariance.resize(_populationSize);
    for (size_t i = 0; i < _populationSize; i++) _chainLeadersCovariance[i].resize(_k->_variables.size() * _k->_variables.size());
    _sampleCovariancesDatabase.resize(_populationSize);
    for (size_t i = 0; i < _populationSize; i++) _sampleCovariancesDatabase[i].resize(_k->_variables.size());

    _upperExtendedBoundaries.resize(_k->_variables.size());
    _lowerExtendedBoundaries.resize(_k->_variables.size());

    for (size_t d = 0; d < _k->_variables.size(); ++d)
    {
      if (_k->_distributions[_k->_variables[d]->_distributionIndex]->_type != "Univariate/Uniform") korali::Logger::logError("Only 'Univariate/Uniform' priors allowed (is %s).\n", _k->_distributions[_k->_variables[d]->_distributionIndex]->_type.c_str());
      double width = dynamic_cast<korali::distribution::univariate::Uniform *>(_k->_distributions[_k->_variables[d]->_distributionIndex])->_maximum - dynamic_cast<korali::distribution::univariate::Uniform *>(_k->_distributions[_k->_variables[d]->_distributionIndex])->_minimum;
      _upperExtendedBoundaries[d] = dynamic_cast<korali::distribution::univariate::Uniform *>(_k->_distributions[_k->_variables[d]->_distributionIndex])->_maximum + width * _domainExtensionFactor;
      _lowerExtendedBoundaries[d] = dynamic_cast<korali::distribution::univariate::Uniform *>(_k->_distributions[_k->_variables[d]->_distributionIndex])->_minimum - width * _domainExtensionFactor;
    }
  }

  // Init
  _annealingExponent = 0.0;
  _logEvidence = 0.0;
  _coefficientOfVariation = 0.0;
  _maxLoglikelihood = -std::numeric_limits<double>::infinity();
  _chainCount = _populationSize;

  _numCovarianceCorrections = 0;

  _numFinitePriorEvaluations = 0;
  _numFiniteLikelihoodEvaluations = 0;

  _numNegativeDefiniteProposals = 0;
  _numLUDecompositionFailuresProposal = 0;
  _numEigenDecompositionFailuresProposal = 0;
  _numInversionFailuresProposal = 0;
  _numCholeskyDecompositionFailuresProposal = 0;

  // Initializing Chain Length first Generation
  std::fill(std::begin(_chainLengths), std::end(_chainLengths), 1);
}

void korali::solver::TMCMC::runGeneration()
{
  if (_k->_currentGeneration == 1) setInitialConfiguration();

  prepareGeneration();
  std::vector<korali::Sample> samples(_chainCount);

  while (_finishedChainsCount < _chainCount)
  {
    for (size_t c = 0; c < _chainCount; c++)
    {
      if (_currentChainStep[c] < _chainLengths[c] + _currentBurnIn)
        if (_chainPendingEvaluation[c] == false)
        {
          _chainPendingEvaluation[c] = true;
          samples[c]["Module"] = "Problem";
          samples[c]["Operation"] = "Evaluate";
          samples[c]["Parameters"] = _chainCandidates[c];
          samples[c]["Sample Id"] = c;
          _currentChainStep[c]++;
          _modelEvaluationCount++;
          _conduit->start(samples[c]);
        }
    }

    size_t finishedId = _conduit->waitAny(samples);
    //printf("%s\n", samples[finishedId]._js.getJson().dump(2).c_str());
    _chainPendingEvaluation[finishedId] = false;

    try
    {
      _chainCandidatesLogLikelihoods[finishedId] = samples[finishedId]["logLikelihood"];
    }
    catch (const std::exception &e)
    {
      korali::Logger::logError("TMCMC: Dev Error - Missing or incorrect value of 'logLikelihood' returned by the sample evaluation. \n   + Solution: Make sure the problem is storing this result, e.g., sample[\"logLikelihood\"] = value.\n   + Cause: %s\n", e.what());
    }

    try
    {
      _chainCandidatesLogPriors[finishedId] = samples[finishedId]["logPrior"];
    }
    catch (const std::exception &e)
    {
      korali::Logger::logError("TMCMC: Dev Error - Missing or incorrect value of 'logPrior' returned by the sample evaluation. \n   + Solution: Make sure the problem is storing this result, e.g., sample[\"logPrior\"] = value.\n   + Cause: %s\n", e.what());
    }

    if (isfinite(_chainCandidatesLogPriors[finishedId])) _numFinitePriorEvaluations++;
    if (isfinite(_chainCandidatesLogLikelihoods[finishedId])) _numFiniteLikelihoodEvaluations++;

    if (_version == "TMCMC") processCandidate(finishedId);
    if (_currentChainStep[finishedId] == _chainLengths[finishedId] + _currentBurnIn) _finishedChainsCount++;
  }

  if (_version == "mTMCMC")
  {
    if (_k->_currentGeneration > 1)
    {
      calculateStepSize();
      calculateGradients(samples);
      calculateProposals(samples);
    }
    for (size_t sampleId = 0; sampleId < _populationSize; ++sampleId) processCandidate(sampleId);
  }

  processGeneration();

  (*_k)["Results"]["Sample Database"] = _sampleDatabase;
}

void korali::solver::TMCMC::prepareGeneration()
{
  setBurnIn();

  _acceptedSamplesCount = 0;
  _finishedChainsCount = 0;
  _maxLoglikelihood = -std::numeric_limits<double>::infinity();

  _sampleLogLikelihoodDatabase.clear();
  _sampleLogPriorDatabase.clear();
  _sampleDatabase.clear();

  _numFinitePriorEvaluations = 0;
  _numFiniteLikelihoodEvaluations = 0;

  if (_version == "mTMCMC")
  {
    _numCovarianceCorrections = 0;
    _numNegativeDefiniteProposals = 0;
    _numLUDecompositionFailuresProposal = 0;
    _numEigenDecompositionFailuresProposal = 0;
    _numInversionFailuresProposal = 0;
    _numCholeskyDecompositionFailuresProposal = 0;

    _sampleErrorDatabase.clear();
    _sampleGradientDatabase.clear();
    _sampleCovariancesDatabase.clear();
    if (_k->_currentGeneration > 1)
      std::fill(_chainCandidatesErrors.begin(), _chainCandidatesErrors.end(), 0);
    else
      std::fill(_chainCandidatesErrors.begin(), _chainCandidatesErrors.end(), -1);

    // annealing
    for (size_t i = 0; i < _populationSize; ++i)
    {
      gsl_matrix_view covLeader = gsl_matrix_view_array(&_chainLeadersCovariance[i][0], _k->_variables.size(), _k->_variables.size());
      gsl_matrix_scale(&covLeader.matrix, _previousAnnealingExponent / _annealingExponent);

      gsl_vector_view gradLeader = gsl_vector_view_array(&_chainLeadersGradients[i][0], _k->_variables.size());
      gsl_vector_scale(&gradLeader.vector, _annealingExponent / _previousAnnealingExponent);
    }
  }

  std::fill(_currentChainStep.begin(), _currentChainStep.end(), 0);
  std::fill(_chainPendingEvaluation.begin(), _chainPendingEvaluation.end(), false);

  std::vector<double> zeroMean(_k->_variables.size(), 0.0);
  _multivariateGenerator->_meanVector = zeroMean;
  _multivariateGenerator->_sigma = _covarianceMatrix;

  /* Cholesky Decomp */
  gsl_matrix_view sigma = gsl_matrix_view_array(&_multivariateGenerator->_sigma[0], _k->_variables.size(), _k->_variables.size());
  gsl_linalg_cholesky_decomp(&sigma.matrix);

  _multivariateGenerator->updateDistribution();

  for (size_t i = 0; i < _populationSize; i++)
  {
    if (_k->_currentGeneration == 1)
    {
      for (size_t d = 0; d < _k->_variables.size(); d++)
        _chainCandidates[i][d] = _k->_distributions[_k->_variables[d]->_distributionIndex]->getRandomNumber();
    }
    else
    {
      generateCandidate(i);
    }
  }
}

void korali::solver::TMCMC::processCandidate(const size_t sampleId)
{
  double P = calculateAcceptanceProbability(sampleId);
  double U = _uniformGenerator->getRandomNumber();

  if (P > U || _k->_currentGeneration == 1)
  {
    _chainLeaders[sampleId] = _chainCandidates[sampleId];
    _chainLeadersLogPriors[sampleId] = _chainCandidatesLogPriors[sampleId];
    _chainLeadersLogLikelihoods[sampleId] = _chainCandidatesLogLikelihoods[sampleId];
    if (_version == "mTMCMC")
    {
      _chainLeadersErrors[sampleId] = _chainCandidatesErrors[sampleId];
      _chainLeadersGradients[sampleId] = _chainCandidatesGradients[sampleId];
      _chainLeadersCovariance[sampleId] = _chainCandidatesCovariance[sampleId];
    }

    if (_currentChainStep[sampleId] > _currentBurnIn) _acceptedSamplesCount++;
    generateCandidate(sampleId);
  }

  if (_currentChainStep[sampleId] > _currentBurnIn) updateDatabase(sampleId);
}

void korali::solver::TMCMC::processGeneration()
{
  // Compute annealing exponent for next generation
  double fmin = 0, xmin = 0;
  minSearch(_sampleLogLikelihoodDatabase.data(), _populationSize, _annealingExponent, _targetCoefficientOfVariation, xmin, fmin);

  _previousAnnealingExponent = _annealingExponent;

  if (xmin > _previousAnnealingExponent + _maxAnnealingExponentUpdate)
  {
    _k->_logger->logWarning("Normal", "Annealing Step larger than Max Rho Update, updating Annealing Exponent by %f (Max Rho Update). \n", _maxAnnealingExponentUpdate);
    _annealingExponent = _previousAnnealingExponent + _maxAnnealingExponentUpdate;
    _coefficientOfVariation = sqrt(tmcmc_objlogp(_annealingExponent, _sampleLogLikelihoodDatabase.data(), _populationSize, _previousAnnealingExponent, _targetCoefficientOfVariation)) + _targetCoefficientOfVariation;
  }
  else if (xmin < 1.0 && xmin < _previousAnnealingExponent + _minAnnealingExponentUpdate)
  {
    _k->_logger->logWarning("Normal", "Annealing Step smaller than Min Rho Update, updating Annealing Exponent by %f (Min Rho Update). \n", _minAnnealingExponentUpdate);
    _annealingExponent = _previousAnnealingExponent + _minAnnealingExponentUpdate;
    _coefficientOfVariation = sqrt(tmcmc_objlogp(_annealingExponent, &_sampleLogLikelihoodDatabase[0], _populationSize, _previousAnnealingExponent, _targetCoefficientOfVariation)) + _targetCoefficientOfVariation;
  }
  else
  {
    _annealingExponent = xmin;
    _coefficientOfVariation = sqrt(fmin) + _targetCoefficientOfVariation;
  }

  /* Compute weights and normalize*/
  std::vector<double> log_weight(_populationSize);
  std::vector<double> weight(_populationSize);
  for (size_t i = 0; i < _populationSize; i++) log_weight[i] = _sampleLogLikelihoodDatabase[i] * (_annealingExponent - _previousAnnealingExponent);

  const double loglikemax = gsl_stats_max(log_weight.data(), 1, _populationSize);
  for (size_t i = 0; i < _populationSize; i++) weight[i] = exp(log_weight[i] - loglikemax);

  double sum_weight = std::accumulate(weight.begin(), weight.end(), 0.0);
  for (size_t i = 0; i < _populationSize; i++) weight[i] = weight[i] / sum_weight;

  _logEvidence += log(sum_weight) + loglikemax - log(_populationSize);

  /* Sample candidate selections based on database entries */
  std::vector<unsigned int> numselections(_populationSize);
  _multinomialGenerator->getSelections(weight, numselections, _populationSize);

  /* scale weights with number repeated samples */
  for (size_t i = 0; i < _populationSize; i++) weight[i] = weight[i] * numselections[i];

  sum_weight = std::accumulate(weight.begin(), weight.end(), 0.0);

  for (size_t i = 0; i < _populationSize; i++) weight[i] = weight[i] / sum_weight;

  double sum_weight2 = 0.0;
  for (size_t i = 0; i < _populationSize; i++) sum_weight2 += weight[i] * weight[i];

  /* Update mean and covariance */
  for (size_t i = 0; i < _k->_variables.size(); i++)
  {
    _meanTheta[i] = 0;
    for (size_t j = 0; j < _populationSize; j++) _meanTheta[i] += _sampleDatabase[j][i] * weight[j];
  }

  for (size_t i = 0; i < _k->_variables.size(); i++)
  {
    for (size_t j = i; j < _k->_variables.size(); ++j)
    {
      double s = 0.0;
      for (size_t k = 0; k < _populationSize; ++k)
        s += weight[k] * (_sampleDatabase[k][i] - _meanTheta[i]) * (_sampleDatabase[k][j] - _meanTheta[j]);
      _covarianceMatrix[i * _k->_variables.size() + j] = _covarianceMatrix[j * _k->_variables.size() + i] = _covarianceScaling * s / (1.0 - sum_weight2);
    }
  }

  /* Resampling - Init new chains */
  std::fill(std::begin(_chainLengths), std::end(_chainLengths), 0);

  size_t leaderChainLen;
  size_t zeroCount = 0;
  size_t leaderId = 0;
  for (size_t i = 0; i < _populationSize; i++)
  {
    if (numselections[i] == 0) zeroCount++;
    while (numselections[i] > 0)
    {
      _chainLeaders[leaderId] = _sampleDatabase[i];
      _chainLeadersLogPriors[leaderId] = _sampleLogPriorDatabase[i];
      _chainLeadersLogLikelihoods[leaderId] = _sampleLogLikelihoodDatabase[i];
      if (_version == "mTMCMC")
      {
        _chainLeadersErrors[leaderId] = _sampleErrorDatabase[i];
        _chainLeadersGradients[leaderId] = _sampleGradientDatabase[i];
        _chainLeadersCovariance[leaderId] = _sampleCovariancesDatabase[i];
      }

      if (numselections[i] > _maxChainLength)
      {
        /* uniform splitting of chains */
        size_t rest = (numselections[i] % _maxChainLength != 0);
        leaderChainLen = _maxChainLength - rest;
      }
      else
      {
        leaderChainLen = numselections[i];
      }
      _chainLengths[leaderId] = leaderChainLen;
      numselections[i] -= leaderChainLen;
      leaderId++;
    }
  }

  /* Anneal gradients and proposal */
  if (_version == "mTMCMC" && _previousAnnealingExponent > 0.0)
    for (size_t i = 0; i < _populationSize; ++i)
    {
      if (_chainLeadersErrors[i] != 0) continue;
      gsl_vector_view gradLeader = gsl_vector_view_array(&_chainLeadersGradients[i][0], _k->_variables.size());
      gsl_vector_scale(&gradLeader.vector, _annealingExponent / _previousAnnealingExponent);

      gsl_matrix_view covLeader = gsl_matrix_view_array(&_chainLeadersCovariance[i][0], _k->_variables.size(), _k->_variables.size());
      gsl_matrix_scale(&covLeader.matrix, _annealingExponent / _previousAnnealingExponent);
    }

  /* Update acceptance statistics */
  size_t uniqueSelections = _populationSize - zeroCount;
  _proposalsAcceptanceRate = (1.0 * _acceptedSamplesCount) / _populationSize;
  _selectionAcceptanceRate = (1.0 * uniqueSelections) / _populationSize;

  _maxLoglikelihood = *std::max_element(_sampleLogLikelihoodDatabase.begin(), _sampleLogLikelihoodDatabase.end());
  _chainCount = leaderId;
}


void korali::solver::TMCMC::calculateStepSize()
{
  if (_adaptiveStepSize == false) return;

  double t = _proposalsAcceptanceRate/_targetAcceptanceRate;
  double factor = 0.5 + 1.0/(1.0+exp(-3.0*(t-1.0)));
  _stepSize *= factor;

}

void korali::solver::TMCMC::calculateGradients(std::vector<korali::Sample> &samples)
{
  size_t numGradientCalculations = 0.0;
  for (size_t c = 0; c < _chainCount; ++c)
  {
    if (!(std::isfinite(_chainCandidatesLogPriors[c]) && std::isfinite(_chainCandidatesLogLikelihoods[c]))) continue;
    samples[c]["Module"] = "Problem";
    samples[c]["Sample Id"] = c;
    samples[c]["Operation"] = "Evaluate Gradient";
    _conduit->start(samples[c]);
    numGradientCalculations++;
  }

  for (size_t c = 0; c < numGradientCalculations; c++)
  {
    size_t finishedId = _conduit->waitAny(samples);
    for (size_t d = 0; d < _k->_variables.size(); ++d) _chainCandidatesGradients[finishedId][d] = ((double)samples[finishedId]["logLikelihood Gradient"][d]) * _annealingExponent;
  }
}

void korali::solver::TMCMC::calculateProposals(std::vector<korali::Sample> &samples)
{
  size_t numFIMCalculations = 0.0;
  for (size_t c = 0; c < _chainCount; ++c)
  {
    if (!(std::isfinite(_chainCandidatesLogPriors[c]) && std::isfinite(_chainCandidatesLogLikelihoods[c]))) continue;
    samples[c]["Sample Id"] = c;
    samples[c]["Module"] = "Problem";
    samples[c]["Operation"] = "Evaluate Fisher Information";
    _conduit->start(samples[c]);
    numFIMCalculations++;
  }

  int status;
  size_t Nth = _k->_variables.size();
  gsl_vector *ccpy0 = gsl_vector_alloc(Nth);
  gsl_vector *ccpy1 = gsl_vector_alloc(Nth);

  for (size_t c = 0; c < numFIMCalculations; c++)
  {
    size_t finishedId = _conduit->waitAny(samples);
    //printf("%s\n", samples[finishedId]._js.getJson().dump(2).c_str());

    // reset
    std::fill(_chainCandidatesCovariance[finishedId].begin(), _chainCandidatesCovariance[finishedId].end(), 0.0);

    std::vector<double> FIM = samples[finishedId]["Fisher Information"];
    gsl_matrix_view FIMview = gsl_matrix_view_array(&FIM[0], Nth, Nth);

    // scale FIM
    gsl_matrix_scale(&FIMview.matrix, _annealingExponent);

    // invert FIM
    gsl_permutation *perm = gsl_permutation_alloc(Nth);

    int s;
    status = gsl_linalg_LU_decomp(&FIMview.matrix, perm, &s);
    if (status != GSL_SUCCESS)
    {
      _chainCandidatesErrors[finishedId] = 1;
      gsl_permutation_free(perm);
      _numLUDecompositionFailuresProposal++;
      continue;
    }

    gsl_matrix *FIMinv = gsl_matrix_alloc(Nth, Nth);
    status = gsl_linalg_LU_invert(&FIMview.matrix, perm, FIMinv);
    gsl_permutation_free(perm);
    if (status != GSL_SUCCESS)
    {
      _chainCandidatesErrors[finishedId] = 2;
      gsl_matrix_free(FIMinv);
      _numInversionFailuresProposal++;
      continue;
    }

    // eigenvalue decomposition
    gsl_vector *Evals = gsl_vector_alloc(Nth);
    gsl_matrix *Evecs = gsl_matrix_alloc(Nth, Nth);
    gsl_eigen_symmv_workspace *work = gsl_eigen_symmv_alloc(Nth);
    status = gsl_eigen_symmv(FIMinv, Evals, Evecs, work);
    gsl_eigen_symmv_free(work);

    if (status != GSL_SUCCESS)
    {
      _chainCandidatesErrors[finishedId] = 3;
      gsl_matrix_free(FIMinv);
      gsl_vector_free(Evals);
      gsl_matrix_free(Evecs);
      _numEigenDecompositionFailuresProposal++;
      continue;
    }

    double minEval = gsl_vector_min(Evals);
    if (minEval <= 0.0)
    {
      //printf("minEval %lf\n", minEval);
      _chainCandidatesErrors[finishedId] = 4;
      gsl_matrix_free(FIMinv);
      gsl_vector_free(Evals);
      gsl_matrix_free(Evecs);
      _numNegativeDefiniteProposals++;
      continue;
    }

    // correction
    double correction = false;
    double distToUpper, distToLower;
    double len, chi2inv = gsl_cdf_chisq_Pinv(0.68, Nth);

    gsl_vector_const_view candidate = gsl_vector_const_view_array(&_chainCandidates[finishedId][0], Nth);

    for (size_t d = 0; d < Nth; ++d)
    {
      gsl_vector_memcpy(ccpy0, &candidate.vector);
      gsl_vector_memcpy(ccpy1, &candidate.vector);

      double scale = sqrt(gsl_vector_get(Evals, d) * chi2inv);
      double scaleBefore = scale;

      gsl_vector_const_view evec = gsl_matrix_const_column(Evecs, d);
      gsl_blas_daxpy(+1.0 * scale, &evec.vector, ccpy0);
      gsl_blas_daxpy(-1.0 * scale, &evec.vector, ccpy1);

      // measure overshoot & undershoot in all dims
      for (size_t e = 0; e < Nth; ++e)
      {
        distToUpper = _upperExtendedBoundaries[e] - _chainCandidates[finishedId][e];
        distToLower = _chainCandidates[finishedId][e] - _lowerExtendedBoundaries[e];

        len = gsl_vector_get(ccpy0, e) - _upperExtendedBoundaries[e];
        if (len > 0.) scale = std::min(scale, std::abs(1.0 / gsl_vector_get(&evec.vector, e) * distToUpper));

        len = _lowerExtendedBoundaries[e] - gsl_vector_get(ccpy0, e);
        if (len > 0.) scale = std::min(scale, std::abs(1.0 / gsl_vector_get(&evec.vector, e) * distToLower));

        len = gsl_vector_get(ccpy1, e) - _upperExtendedBoundaries[e];
        if (len > 0.) scale = std::min(scale, std::abs(1.0 / gsl_vector_get(&evec.vector, e) * distToUpper));

        len = _lowerExtendedBoundaries[e] - gsl_vector_get(ccpy1, e);
        if (len > 0.) scale = std::min(scale, std::abs(1.0 / gsl_vector_get(&evec.vector, e) * distToLower));
      }

      // scale evals
      gsl_vector_set(Evals, d, scale * scale / chi2inv);
      if (scaleBefore != scale) correction = true;
    }

    if (correction) _numCovarianceCorrections++;

    // construct & store
    for (size_t d = 0; d < Nth; ++d)
    {
      gsl_vector_view evec = gsl_matrix_column(Evecs, d);
      gsl_vector_scale(&evec.vector, sqrt(gsl_vector_get(Evals, d)));
    }

    gsl_matrix_view candidatecov = gsl_matrix_view_array(&_chainCandidatesCovariance[finishedId][0], Nth, Nth);
    gsl_blas_dgemm(CblasNoTrans, CblasTrans, 1.0, Evecs, Evecs, 0.0, &candidatecov.matrix);

    gsl_matrix_free(Evecs);
    gsl_vector_free(Evals);
    gsl_matrix_free(FIMinv);
  }

  gsl_vector_free(ccpy0);
  gsl_vector_free(ccpy1);
}

void korali::solver::TMCMC::generateCandidate(const size_t sampleId)
{
  if (_version == "TMCMC")
  {
    _multivariateGenerator->getRandomVector(&_chainCandidates[sampleId][0], _k->_variables.size());
    for (size_t d = 0; d < _k->_variables.size(); d++) _chainCandidates[sampleId][d] += _chainLeaders[sampleId][d];
  }
  else /* "mTMCMC" */
  {
    // TODO: refine error treatment granularity
    if (_chainLeadersErrors[sampleId] == 0)
    {
      _multivariateGenerator->_meanVector = _chainLeaders[sampleId];
      for (size_t i = 0; i < _k->_variables.size() * _k->_variables.size(); ++i) _multivariateGenerator->_sigma[i] = _chainLeadersCovariance[sampleId][i] * _stepSize;

      /* Cholesky Decomp */
      gsl_matrix_view sigma = gsl_matrix_view_array(&_multivariateGenerator->_sigma[0], _k->_variables.size(), _k->_variables.size());
      int status = gsl_linalg_cholesky_decomp(&sigma.matrix);
      if (status == GSL_SUCCESS)
      {
        _multivariateGenerator->updateDistribution();
        _multivariateGenerator->getRandomVector(&_chainCandidates[sampleId][0], _k->_variables.size());

        gsl_vector_view candidate = gsl_vector_view_array(&_chainCandidates[sampleId][0], _k->_variables.size());
        gsl_vector_const_view leaderGrad = gsl_vector_const_view_array(&_chainLeadersGradients[sampleId][0], _k->_variables.size());
        gsl_matrix_const_view leaderCov = gsl_matrix_const_view_array(&_chainLeadersCovariance[sampleId][0], _k->_variables.size(), _k->_variables.size());
        gsl_blas_dgemv(CblasNoTrans, 0.5 * _stepSize, &leaderCov.matrix, &leaderGrad.vector, 1.0, &candidate.vector);
      }
      else
      {
        _numCholeskyDecompositionFailuresProposal++;
        _chainLeadersErrors[sampleId] = 5;
      }
    }
    if (_chainLeadersErrors[sampleId] != 0) /* error */
    {
      _multivariateGenerator->_meanVector = _chainLeaders[sampleId];
      _multivariateGenerator->_sigma = _covarianceMatrix;

      /* Cholesky Decomp */
      gsl_matrix_view sigma = gsl_matrix_view_array(&_multivariateGenerator->_sigma[0], _k->_variables.size(), _k->_variables.size());
      gsl_linalg_cholesky_decomp(&sigma.matrix);

      _multivariateGenerator->updateDistribution();
      _multivariateGenerator->getRandomVector(&_chainCandidates[sampleId][0], _k->_variables.size());
    }
  }
}

void korali::solver::TMCMC::updateDatabase(const size_t sampleId)
{
  _sampleDatabase.push_back(_chainLeaders[sampleId]);
  _sampleLogPriorDatabase.push_back(_chainLeadersLogPriors[sampleId]);
  _sampleLogLikelihoodDatabase.push_back(_chainLeadersLogLikelihoods[sampleId]);

  if (_version == "mTMCMC")
  {
    _sampleErrorDatabase.push_back(_chainLeadersErrors[sampleId]);
    _sampleGradientDatabase.push_back(_chainLeadersGradients[sampleId]);
    _sampleCovariancesDatabase.push_back(_chainLeadersCovariance[sampleId]);
  }
}

double korali::solver::TMCMC::calculateAcceptanceProbability(const size_t sampleId)
{
  double P = 0.0;
  if (std::isfinite(_chainCandidatesLogPriors[sampleId]) && std::isfinite(_chainCandidatesLogLikelihoods[sampleId]))
    if (_version == "TMCMC")
    {
      P = exp((_chainCandidatesLogLikelihoods[sampleId] - _chainLeadersLogLikelihoods[sampleId]) * _annealingExponent + (_chainCandidatesLogPriors[sampleId] - _chainLeadersLogPriors[sampleId]));
    }
    else /* mTMCMC */
    {
      // TODO: refine error treatment granularity
      if ((_chainLeadersErrors[sampleId] == 0) && (_chainCandidatesErrors[sampleId] == 0))
      {
        gsl_vector_const_view leader = gsl_vector_const_view_array(&_chainLeaders[sampleId][0], _k->_variables.size());
        gsl_vector_const_view candidate = gsl_vector_const_view_array(&_chainCandidates[sampleId][0], _k->_variables.size());

        gsl_vector *meanLeader = gsl_vector_alloc(_k->_variables.size());
        gsl_vector_memcpy(meanLeader, &leader.vector);

        gsl_vector *meanCandidate = gsl_vector_alloc(_k->_variables.size());
        gsl_vector_memcpy(meanCandidate, &candidate.vector);

        gsl_vector_const_view gradLeader = gsl_vector_const_view_array(&_chainLeadersGradients[sampleId][0], _k->_variables.size());
        gsl_vector_const_view gradCandidate = gsl_vector_const_view_array(&_chainCandidatesGradients[sampleId][0], _k->_variables.size());

        gsl_matrix_const_view covLeader = gsl_matrix_const_view_array(&_chainLeadersCovariance[sampleId][0], _k->_variables.size(), _k->_variables.size());

        gsl_blas_dgemv(CblasNoTrans, 0.5 * _stepSize, &covLeader.matrix, &gradLeader.vector, 1.0, meanLeader);
        gsl_blas_dgemv(CblasNoTrans, 0.5 * _stepSize, &covLeader.matrix, &gradCandidate.vector, 1.0, meanCandidate);

        gsl_matrix *cholCovLeader = gsl_matrix_alloc(_k->_variables.size(), _k->_variables.size());
        gsl_matrix_memcpy(cholCovLeader, &covLeader.matrix);
        gsl_matrix_scale(cholCovLeader, _stepSize);
        int status = gsl_linalg_cholesky_decomp1(cholCovLeader);

        gsl_vector *work = gsl_vector_alloc(_k->_variables.size());

        double logpCandidate, logpLeader;
        gsl_ran_multivariate_gaussian_log_pdf(&candidate.vector, meanLeader, cholCovLeader, &logpCandidate, work);
        gsl_ran_multivariate_gaussian_log_pdf(&leader.vector, meanCandidate, cholCovLeader, &logpLeader, work);

        gsl_vector_free(work);
        gsl_matrix_free(cholCovLeader);
        gsl_vector_free(meanLeader);
        gsl_vector_free(meanCandidate);

        P = exp((_chainCandidatesLogLikelihoods[sampleId] - _chainLeadersLogLikelihoods[sampleId]) * _annealingExponent + (logpLeader - logpCandidate) + (_chainCandidatesLogPriors[sampleId] - _chainLeadersLogPriors[sampleId]));
      }
      else /* error */
      {
        P = exp((_chainCandidatesLogLikelihoods[sampleId] - _chainLeadersLogLikelihoods[sampleId]) * _annealingExponent + (_chainCandidatesLogPriors[sampleId] - _chainLeadersLogPriors[sampleId]));
      }
    }
  return P;
}

double korali::solver::TMCMC::tmcmc_objlogp(double x, const double *loglike, size_t Ns, double exponent, double targetCOV)
{
  std::vector<double> weight(Ns);
  const double loglike_max = gsl_stats_max(loglike, 1, Ns);

  for (size_t i = 0; i < Ns; i++) weight[i] = exp((loglike[i] - loglike_max) * (x - exponent));

  double sum_weight = std::accumulate(weight.begin(), weight.end(), 0.0);

  for (size_t i = 0; i < Ns; i++) weight[i] = weight[i] / sum_weight;

  double mean = gsl_stats_mean(weight.data(), 1, Ns);
  double std = gsl_stats_sd_m(weight.data(), 1, Ns, mean);
  double cov2 = (std / mean) - targetCOV;
  cov2 *= cov2;

  if (isfinite(cov2) == false)
    return korali::Lowest;
  else
    return cov2;
}

double korali::solver::TMCMC::objLog(const gsl_vector *v, void *param)
{
  double x = gsl_vector_get(v, 0);
  fparam_t *fp = (fparam_t *)param;
  return korali::solver::TMCMC::tmcmc_objlogp(x, fp->loglike, fp->Ns, fp->exponent, fp->cov);
}

void korali::solver::TMCMC::minSearch(double const *loglike, size_t Ns, double exponent, double objCov, double &xmin, double &fmin)
{
  // Minimizer Options
  const size_t MaxIter = 1000; /* Max number of search iterations */
  const double Tol = 1e-12;    /* Tolerance for root finding */
  const double Step = 1e-8;    /* Search stepsize */

  const gsl_multimin_fminimizer_type *T;
  gsl_multimin_fminimizer *s = NULL;
  gsl_vector *ss, *x;
  gsl_multimin_function minex_func;

  size_t iter = 0;
  int status;
  double size;

  fparam_t fp;
  fp.loglike = loglike;
  fp.Ns = Ns;
  fp.exponent = exponent;
  fp.cov = objCov;

  x = gsl_vector_alloc(1);
  gsl_vector_set(x, 0, exponent);

  ss = gsl_vector_alloc(1);
  gsl_vector_set_all(ss, Step);

  minex_func.n = 1;
  minex_func.f = objLog;
  minex_func.params = &fp;

  T = gsl_multimin_fminimizer_nmsimplex;
  s = gsl_multimin_fminimizer_alloc(T, 1);
  gsl_multimin_fminimizer_set(s, &minex_func, x, ss);

  fmin = 0;
  xmin = 0.0;

  do
  {
    iter++;
    status = gsl_multimin_fminimizer_iterate(s);
    size = gsl_multimin_fminimizer_size(s);
    status = gsl_multimin_test_size(size, Tol);
  } while (status == GSL_CONTINUE && iter < MaxIter);

  if (status == GSL_SUCCESS && s->fval > Tol) _k->_logger->logWarning("Normal", "Min Search converged but did not find minimum. \n");
  if (status != GSL_SUCCESS && s->fval <= Tol) _k->_logger->logWarning("Normal", "Min Search did not converge but minimum found\n");
  if (status != GSL_SUCCESS && s->fval > Tol) _k->_logger->logWarning("Normal", "Min Search did not converge and did not find minimum\n");
  if (iter >= MaxIter) _k->_logger->logWarning("Normal", "Min Search MaxIter (%zu) reached\n", MaxIter);

  if (s->fval <= Tol)
  {
    fmin = s->fval;
    xmin = gsl_vector_get(s->x, 0);
  }

  if (xmin >= 1.0)
  {
    fmin = tmcmc_objlogp(1.0, loglike, Ns, exponent, objCov);
    xmin = 1.0;
  }

  gsl_vector_free(x);
  gsl_vector_free(ss);
  gsl_multimin_fminimizer_free(s);
}

void korali::solver::TMCMC::setBurnIn()
{
  if (_k->_currentGeneration == 1)
    _currentBurnIn = 0;
  else if (_k->_currentGeneration < _perGenerationBurnIn.size())
    _currentBurnIn = _perGenerationBurnIn[_k->_currentGeneration];
  else
    _currentBurnIn = _defaultBurnIn;
}

void korali::solver::TMCMC::finalize()
{
}

void korali::solver::TMCMC::printGenerationBefore()
{
  _k->_logger->logInfo("Minimal", "Annealing Exponent:          %.3e.\n", _annealingExponent);
}

void korali::solver::TMCMC::printGenerationAfter()
{
  _k->_logger->logInfo("Minimal", "Acceptance Rate (proposals / selections): (%.2f%% / %.2f%%)\n", 100 * _proposalsAcceptanceRate, 100 * _selectionAcceptanceRate);
  _k->_logger->logInfo("Normal", "Coefficient of Variation: %.2f%%\n", 100.0 * _coefficientOfVariation);
  _k->_logger->logInfo("Normal", "logEvidence: %.3f\n", _logEvidence);
  _k->_logger->logInfo("Detailed", "max logLikelihood: %.3f\n", _maxLoglikelihood);
  _k->_logger->logInfo("Detailed", "Number of finite evaluations (prior / likelihood): (%zu / %zu)\n", _numFinitePriorEvaluations, _numFiniteLikelihoodEvaluations);

  if (_version == "mTMCMC")
  {
    if(_adaptiveStepSize) _k->_logger->logInfo("Detailed", "Step Size: %lf\n", _stepSize);
    _k->_logger->logInfo("Normal", "Number Of Covariance Corrections: %zu\n", _numCovarianceCorrections);
    _k->_logger->logInfo("Detailed", "Number Of LU Decomposition Errors: %zu\n", _numLUDecompositionFailuresProposal);
    _k->_logger->logInfo("Detailed", "Number Of Eigenvalue Errors: %zu\n", _numEigenDecompositionFailuresProposal);
    _k->_logger->logInfo("Detailed", "Number Of FIM Inversion Errors: %zu\n", _numInversionFailuresProposal);
    _k->_logger->logInfo("Detailed", "Number Of Negative Definite Proposals: %zu\n", _numNegativeDefiniteProposals);
    _k->_logger->logInfo("Detailed", "Number Of Cholesky Decomposition Errors: %zu\n", _numCholeskyDecompositionFailuresProposal);
  }

  _k->_logger->logInfo("Detailed", "Sample Mean:\n");
  for (size_t i = 0; i < _k->_variables.size(); i++) _k->_logger->logData("Detailed", " %s = %+6.3e\n", _k->_variables[i]->_name.c_str(), _meanTheta[i]);
  _k->_logger->logInfo("Detailed", "Sample Covariance:\n");

  for (size_t i = 0; i < _k->_variables.size(); i++)
  {
    _k->_logger->logData("Detailed", "   | ");
    for (size_t j = 0; j < _k->_variables.size(); j++)
      if (j <= i)
        _k->_logger->logData("Detailed", "%+6.3e  ", _covarianceMatrix[i * _k->_variables.size() + j]);
      else
        _k->_logger->logData("Detailed", "     -      ");
    _k->_logger->logData("Detailed", " |\n");
  }
}
